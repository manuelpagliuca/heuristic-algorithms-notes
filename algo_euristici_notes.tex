\documentclass{article}
\usepackage{newunicodechar}
\usepackage[OT1]{fontenc}
\usepackage{mathpazo}
\usepackage[italian]{babel}
\usepackage{caption}
\usepackage[dvipsnames]{xcolor}
\usepackage{fancyhdr}
\fancyhead{}
\renewcommand{\headrulewidth}{0pt} % Width of line at top of page
\fancyhead[L]{\leftmark} % Mark right [R] of page with Chapter name [\leftmark]

\pagestyle{fancy} % Set default style for all content pages (not TOC, etc)

%Prefisso della caption delle figure
\captionsetup[figure]{labelformat=empty}% redefines the caption setup of the figures environment in the beamer class.

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
%Codice
\usepackage{listings}
\usepackage{algpseudocode}
\usepackage{algorithm}


\newcommand{\ovcal}[1]{\overline{\mathcal{#1}}}


\title{\textbf{Algoritmi Euristici}}
\author{Manuel Pagliuca}

\begin{document}

\maketitle
\pagebreak
\tableofcontents
\pagebreak
\section{Introduzione}
L'obiettivo di questo corso è quello di mostrare che gli \textbf{algoritmi euristici} non sono ricette per problemi specifici:
le euristiche e i problemi possono essere combinati liberamente.
Una qualsiasi euristica può essere utilizzata su un qualsiasi problema. \textit{Euristica} è una parola che deriva dal Greco,
e sta per \textit{"metodologia di ricerca della verità o dei fatti"}, deriva da \textit{heurìsko} che significa \textit{io trovo}.

Il termine deriva da una storia molto famosa di Archimede, che aveva da risolvere il problema di imparare se la data corona d'oro era effettivamente
d'oro o se fosse solo placcata in oro. Questo era possibile da dedurre conoscendo il rapporto tra peso e volume, però il peso era facile da ottenere,
mentre il volume è molto più difficile.

L'idea di Archimede consisteva nell'utilizzo di un secchio colmo di acqua ed immergendo la corona in quest'ultimo, il quantitativo di acqua che esce
dal secchio consiste nel volume della corona.
\section{Algoritmi euristici}
\subsection{Cenni sulla parola}
La parola \textit{euristica} può cambiare di significato in base al campo in cui viene utilizzata, in alcuni settori scientifici la parola \textit{algoritmo euristico}
è considerata come \textbf{ossimoro} in quanto le due parole vengono considerate opposti.
\begin{itemize}
    \item \textbf{Algoritmo} ha un significato che sta per \textit{procedura deterministica} e \textit{formale}, la quale consiste in una sequenza finita di step elementari.
    \item \textbf{Euristico} ha un significato che sta per \textit{informale, creativo} e \textit{metodo a "regola aperta"} per trovare una soluzione.
\end{itemize}

Ogni algoritmo ha (od è) una \textbf{dimostrazione di correttezza} mentre un algoritmo euristico non ne ha nessuna.
Essi sono trasformazioni meccanico-simboliche che partono da uno \textit{starting point} (chiamato \textit{ipotesi}) e giungono ad un \textit{end point}(chiamato \textit{tesi}).

\subsection{Definizione}
Gli algoritmi euristici sono procedure formali dove la soluzione non è garantita essere quella \textbf{corretta}. Questo potrebbe sembrare inutile,
ma al contrario potrebbe essere utile per diversi motivi:
\begin{enumerate}
    \item \textbf{Costa} molto meno di un algoritmo corretto, in termini di \textit{spazio} e \textit{tempo}.
    \item Frequentemente \textbf{restituisce} qualcosa di \underline{vicino} alla soluzione corretta.
\end{enumerate}

Per definire la \textit{vicinanza} della soluzione, lo \textbf{spazio delle soluzioni} sarà dotato di una \textit{metrica} per esprimere una \textit{distanza soddisfacente}
della soluzione corrente dalla soluzione corretta.
Inoltre sarà dotato di una \textbf{distribuzione probabilistica} per esprimere la frequenza soddisfacente delle soluzioni che si trovano ad una distanza soddisfacente dalla
soluzione corretta (ovvero esprime quanto spesso l'algoritmo restituisce una soluzione soddisfacente).

\subsection{Motivazioni per gli algoritmi euristici}
Le euristiche sono la costruzione sia delle \textbf{dimostrazioni} che degli \textbf{algoritmi}, in caso di successo l'euristica viene abbandonata e la
\textit{dimostrazione} viene preservata. Altrimenti, una buona euristica solitamente porta ad un buon risultato, seppur non perfetto.
\section{Classificazione dei problemi}
Questo corso è incentrato su gli algoritmi euristici applicati ai problemi di \textbf{ottimizzazione combinatoria} che sono \textbf{basati su soluzioni}
(contrapposti a quelli \textbf{basati sui modelli}).

Un problema è una domanda che viene effettuata su un \textbf{sistema matematico}, la tipologia dei problemi viene classificata in base alla natura delle loro soluzioni.
\begin{enumerate}
    \item \textbf{problemi di decisione}: la loro soluzione è un booleano.
    \item \textbf{problemi di ricerca}: la loro soluzione è un qualsiasi sottoinsieme \textit{fattibile}.
    \item \textbf{problemi di ottimizzazione}: la loro soluzione è un numero il quale è il \textit{minimo} o \textit{massimo} valore di una \textbf{funzione oggettiva}
          definita su dei sottoinsiemi fattibili.
    \item \textbf{problemi di conteggio}: la loro soluzione è il \textit{numero} di sottoinsiemi \textit{fattibili}.
    \item \textbf{problemi di enumerazione}: la loro soluzione è la collezione di tutti i sottoinsiemi \textit{fattibili}.
\end{enumerate}
I problemi di ottimizzazione possono essere combinati con i problemi di ricerca, noi ci concentreremo su questo tipo di problemi, ovvero siamo alla ricerca del
\textbf{valore ottimale} e del \textbf{sottosistema che assume} quel valore.

\subsection{Problemi di ottimizzazione e ricerca}

Un problema di ottimizzazione e ricerca può essere rappresentato con:
$$opt_{x\in X}f(x)$$
Dove $x$ rappresenta una \textbf{sottosistema fattibile} che è una delle soluzioni, la quale soddisfa le condizioni fornite dal problema. Invece, $X$
è lo \textbf{spazio delle soluzioni fattibili}. Invece la funzione, si chiama \textbf{funzione oggettiva} ed è mappata in questa maniera $f:X \rightarrow R$,
il suo compito è quello di \textit{misurare quantitativamente} la qualità di ogni sottosistema (o soluzione).
Generalmente, in quanto problema di ottimizzazione, la funzione oggettiva è \textit{massimizzabile} o \textit{minimizzabile}, questo viene denotato con $opt\in {min,max}$.

Il problema consiste nel determinare il \textbf{valore ottimale della funzione oggettiva} assieme alla \textbf{soluzione ottima} tale che sia un sottoinsieme. Il valore ottimale della funzione oggettiva viene chiamato $f^*$, ed è il risultato della seguente equazione:
$$f^*=opt_{x\in X}f(x)$$
Ovvero un valore che consiste nel minimo o massimo della funzione oggettiva. Mentre, la soluzione ottima tale che sia un sottoinsieme si chiamerà $x^*$:
$$x^*\in X^*=arg\textit{ } opt_{x\in X}f(x)={x^* \in X : f(x^*)=opt_{x\in X}f(x)}$$
Ovvero, vogliamo trovare una soluzione ottima nell'intero insieme di tutte le soluzioni ottime, anche se solitamente una è abbastanza, la notazione $arg$
sta per l'intero insieme delle soluzioni (ne basta una).

\subsection{perché siamo interessati nei problemi di ottimizzazione e ricerca ?}

I problemi di ottimizzazione e ricerca sono di forte interesse poiché diversi campi applicativi richiedono oggetti o strutture caratterizzati da valori molto alti o molto bassi rispetto ad una propria funzione di valutazione.
\begin{itemize}
    \item Bioinformatica
    \item Social networks
    \item Machine learning
    \item Hardware design
    \item Stima dei parametri
    \item Finanza
\end{itemize}

L'\textbf{ottimizzazione esatta} è costosa da un punto di vista computazionale e non sempre desiderabile (per questo gli algoritmi euristici sono favoriti);
perciò, solitamente, le funzioni di valutazione sono delle \textit{approssimazioni} di quello che realmente accade. In questo corso assumeremo il punto di vista dell'ottimizzazione, cercando di ottimizzare al meglio possibile la funzione oggettiva.

Diversi problemi possono spesso essere ridotti in problemi di ottimizzazione e ricerca
\begin{itemize}
    \item \textit{Problemi di ricerca} possono essere ridotti rilassando le condizioni da soddisfare, in maniera da allargare la \textbf{regione di fattibilità}
          da $X$ a $X'\supset X$ ed ottenere un problema di ricerca semplice. Si introduce una funzione $d(x)$ per quantificare la distanza di ogni soluzione $x\in X'$ da $X$. Infine, minimizzando $d(x)$ per trovare $x^*$ tale che $d(x^*)=0 \Leftrightarrow x^* \in X$.
    \item Alcuni \textit{problemi di decisione} riguardano l'esistenza di sottosistemi fattibili, e sono identici ai problemi di
          ricerca (trovare il sottosistema dimostra la sua esistenza).
    \item Alcuni \textit{problemi di numerazione} riguardano la ricerca di sottosistemi con \textit{"buoni"} valori di funzioni oggettive in conflitto e permettono
          \textit{adattamenti diretti} ad algoritmi di ottimizzazione e ricerca.
\end{itemize}
Tali riduzioni sono spesso possibili ed utili, ma non sempre.
\subsection{Problema di ottimizzazione combinatoria}
Un problema è un problema CO (\textit{Combinatorial Optimization}) quando la regione di fattibilità \textit{X} è un insieme finito, e quindi, che abbia un numero
finito di \textit{soluzioni fattibili}. Questa sembra un'assunzione molto restrittiva, ma sono presenti molti
problemi che hanno un numero infinito di soluzioni che possono essere ridotti a problemi che hanno un numero finito di soluzioni.

Per esempio:
\begin{itemize}
    \item I problemi infiniti nel discreto possono avere un insieme finito di soluzioni interessanti.
    \item Alcuni problemi continui possono essere ridotti a problemi di ottimizzazione combinatoria: \textit{Programmazione lineare, Flusso massimo, Costo minimo di flusso, ...}.
    \item I problemi continui possono essere ridotto in discreto utilizzando il campionamento (solitamente non è molto efficace).
    \item Le idee concepite per i problemi CO possono essere estese ad altri problemi.
\end{itemize}

\subsection{Euristiche basate sui modelli}
In questo corso parleremo solamente di \textbf{euristiche basate su soluzioni}, ma è importante conoscere anche la controparte.
L'euristiche basate sui modelli descrivono la regione di fattibilità $X$ con un "modello", un esempio tipico è una funzione matematica.
$$opt_{x\in X} f(x) \rightarrow \text{min}_{g_i(\xi)\leq 0}\phi(\xi) \text{ per } i=1,...,m$$

Dove $\xi \in \mathbb{R}^n$, il quale è il vettore delle soluzioni di $n$ numeri reali. Mentre $X={\xi \in \mathbb{R}^n : g_i(\xi)\leq 0, i=1,...,m}$, ovvero che la
regione di fattibilità è l'insieme dei vettori che soddisfanno tutte le disuguaglianze.
L'euristiche basate su modelli estrapolano l'informazione derivata dal modello, che sono le proprietà analitiche della funzione $\phi$ e $g_i \text{ per } i=1,...m$.

\subsection{Definizione alternativa di CO}
Una problema è un problema CO() quando:
\begin{enumerate}
    \item Il numero di soluzioni fattibili è finito (prima definizione).
    \item La regione di fattibilità è $X\subseteq 2^B$ per un dato \textbf{ground set} $B$, ovvero, le \textit{soluzioni fattibili} sono tutte sottoinsiemi del ground set che
          soddisfa le condizioni adeguate.
\end{enumerate}

Entrambe le definizioni sono equivalenti:
\begin{itemize}
    \item $2 \implies 1$: se il ground set $B$ è finito, ogni collezione $X\subseteq 2^B$ è finita.
    \item $1 \implies 2$: se il numero di soluzioni fattibili è finito, definire $B$ come il loro sovrainsieme ed $X$ la \textit{regione fattibile} sarà la
          collezione dei singoli elementi di $B$ (una \textit{"soluzione"} è un insieme contenente una singola soluzione).
\end{itemize}
In generale, la definizione sofisticata permette un analisi più profonda, perché $X$ non viene semplicemente numerato
e viene definito in una maniera \textit{compatta} e \textit{significativa}.

\subsection{Euristiche basate su soluzioni}
L'euristiche basate su soluzioni considerano le soluzioni come sottoinsiemi del ground set, esse possono essere classificate in:
\begin{enumerate}
    \item \textbf{Euristiche costruttive/distruttive}, iniziano da un sottoinsieme estremamente semplice
          (può essere $\emptyset$ o $B$), poi, esse aggiungono/rimuovono gli elementi fino a che non ottengono la soluzione desiderata.
    \item \textbf{Euristiche di scambio}, iniziano da un sottoinsieme ottenuto in una qualsiasi maniera,
          poi, scambiano gli elementi fino a che non ottengono la soluzione desiderata.
    \item \textbf{Euristiche di ricombinazione}, iniziano da una popolazione di sottoinsiemi ottenuta in una qualsiasi maniera,
          poi, ricombinando differenti sottoinsiemi produrranno una \textit{nuova} popolazione.
\end{enumerate}

I progettisti delle euristiche possono combinare in maniera creativa gli elementi delle diverse classi delle euristiche.

\subsubsection{Randomizzazione e memoria}
Sono presenti due cose importanti che intervengono nella progettazione di un algoritmo:
\begin{itemize}
    \item \textbf{Randomizzazione}
    \item \textbf{Memoria}
\end{itemize}

Puoi avere algoritmi che usano o non usano la randomizzazione o la memoria.
Questi due elementi sono ortogonali (indipendenti) rispetto alla classificazione delle euristiche basate sulle soluzioni, per ognuna di esse possiamo dire che abbiamo quattro sottoclassi.

\begin{enumerate}
    \item Utilizzo della randomizzazione:
          \begin{itemize}
              \item \textbf{Euristiche puramente deterministiche}
              \item \textbf{Euristiche \textit{"randomizzate"}}, essenzialmente sono algoritmi che utilizzano come input numeri pseudo-casuali.
          \end{itemize}
    \item Utilizzo della memoria:
          \begin{itemize}
              \item Euristiche dove l'input include solamente i \textbf{dati del problema}.
              \item Euristiche dove l'input include anche \textbf{soluzioni precedentemente generate}.
          \end{itemize}
\end{enumerate}

Comunemente si utilizza il termine \textit{metaeuristiche} (dal Greco, \textit{"oltre le euristiche"}) per descrivere gli algoritmi euristici
che vanno utilizzano la randomizzazione e/o la memoria.

\subsection{Rischi da cui stare attenti}
\begin{enumerate}
    \item \textbf{Attitudine reverenziale o alla tendenza}, ovvero, nello scegliere un algoritmo basato sul contesto sociale, anziché sul problema.
    \item \textbf{Attitudine magica}, ovvero, \textit{credere} in un metodo sulla base di un analogia con un fenomeno fisico e naturale.
    \item \textbf{Integralismo euristico}, ovvero, utilizzare un euristica per un problema che ammette l'utilizzo di un algoritmo esatto.
    \item \textbf{Sgranocchiare numeri}, ovvero, eseguire sofisticati e complessi calcoli con numeri inaffidabili.
    \item \textbf{Attitudine SUV}, ovvero, affidarsi alla potenza dell'hardware.
    \item \textbf{Complicare ulteriormente}, ovvero, introdurre componenti e parametri \textit{ridondanti}, per cercare (fallendo) di migliorare il risultato.
    \item \textbf{Overfitting}, ovvero, adattare i componenti ed i parametri dell'algoritmo ad un dataset specifico utilizzato nella valutazione sperimentale.
\end{enumerate}

Inoltre è fondamentale:
\begin{itemize}
    \item Liberarsi dai pregiudizi.
    \item Valutare le prestazioni dell'algoritmo in una maniera scientifica.
    \item Distinguere il contributo di ogni componente dell'algoritmo.
    \item Implementare efficientemente ogni componente dell'algoritmo.
\end{itemize}

\section{Problemi di ottimizzazione combinatoria}
Il ground set è la base sul quale si costruisce l'algoritmo, abbiamo visto che sono presenti molteplici possibilità con le
euristiche basate sulle soluzioni, la loro classe cambierà in base al ground set utilizzato.
Quindi per prima cosa dobbiamo capire che cosa è (\textit{tipologia}) il \textbf{ground set}.

Visiteremo inizialmente un certo numero di problemi, questo sarà utile perché:
\begin{itemize}
    \item Le idee astratte devono essere applicate concretamente su diversi algoritmi per diversi problemi.
    \item La stessa idea può avere differente efficacia su diversi problemi.
    \item Alcune idee funzionano solamente su problemi con una specifica struttura.
    \item Diversi problemi potrebbero non avere un apparente relazione, cosa che può essere sfruttata per progettare algoritmi.
\end{itemize}

Una buona conoscenza di diversi problemi ci insegna ad applicare le idee astratte a nuovi problemi e ci insegna come trovare e sfruttare le relazioni tra problemi conosciuti e nuovi.

\subsection{Insieme dei problemi pesati}
\subsubsection{Knapsack Problem (KP)}
Il problema dello zaino, \textit{Knapsack Problem}. Il problema consiste nell'avere a disposizione uno zaino che ha una \textit{capacità limitata} ed un insieme di oggetti con differenti
\textit{volumi} e \textit{valori}, si vuole riempire lo zaino con gli oggetti di valore massimo (ovviamente non si può mettere dentro tutti gli oggetti).

Dati:
\begin{itemize}
    \item Insieme elementare $E$ di oggetti.
    \item Una funzione $v:E\rightarrow \mathbb{N}$ che descrive il \textbf{volume} di ogni oggetto.
    \item Un numero $V\in \mathbb{N}$ che descrive la \textbf{capacità} dello zaino.
    \item Una funzione $\phi : E\rightarrow \mathbb{N}$ che descrive il \textbf{valore} di ogni oggetto.
\end{itemize}

Banalmente, il \textbf{ground set} è l'insieme degli oggetti $B\equiv E$. La \textbf{regione di fattibilità} include tutti i sottoinsiemi degli
oggetti il cui volume totale non eccede la capacità $V$ dello zaino.
$$X=\left\{x\subseteq B : \sum_{j\in x}v_j \leq V\right\}$$

L'obiettivo è quello di massimizzare il valore totale degli oggetti scelti:
$$max_{x\in X} f(x)=\sum_{j\in x}\phi_j$$

Per esempio, nella seguente tabella sono mostrati tutti gli elementi di $E$ con i relativi valori e volumi. Sapendo che lo zaino ha una capacità massima $V=8$, consideriamo due \textbf{soluzioni candidate}:

\begin{figure}[H]
    \centering
    \includegraphics[width=6cm]{images/tab_KP.png}
    \caption{Dataset}
    \label{fig:tab_KP}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=6cm]{images/graphic_KP.png}
    \caption{Raffigurazione problema dello zaino}
    \label{fig:graphic_KP}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=8cm]{images/cand_sol_KP.png}
    \caption{Soluzioni candidate}
    \label{fig:cand_sol_KP}
\end{figure}

\begin{itemize}
    \item La prima soluzione candidata considera tre elementi la cui somma è $\leq V$, questo significa che la
          soluzione è un sottoinsieme preso dalla regione di fattibilità $X$ ed è una \textbf{soluzione fattibile}.
    \item La seconda soluzione candidata ha una somma di elementi pari a $10$, la quale è $>V$. Quindi questo sotto insieme
          non è appartenente alla regione di fattibilità $X$ (ma solo al ground set), perciò verrà chiamata \textbf{soluzione infattibile}.
\end{itemize}

Tra le soluzioni fattibili proposte la \textbf{funzione oggettiva} propone di prendere la soluzione \textit{massima}, ma visto che $x''$ non è fattibile, prenderemo come soluzione $x'$.
\subsubsection{Maximum Diversity Problem (MDP)}
Il problema della diversità massima, \textit{Maximum Diversity Problem}, è un problema importante per il corso e
verrà utilizzato come esempio per la parte di laboratorio. Questo è un problema
definito su uno spazio metrico, quindi uno spazio con la nozione di \textit{distanza}.

Dati:
\begin{itemize}
    \item Un insieme di punti $P$.
    \item Una funzione $d:P \times P \rightarrow \mathbb{N}$, la quale provvede la distanza tra le coppie di punti.
    \item Un numero $k\in {1,...,|P|}$, il quale è il numero di punti che si vuole selezionare.
\end{itemize}

Il problema chiede di selezionare da un insieme di punti $P$ un sottoinsieme di $k$ punti la cui sommatoria delle distanze tra le coppie dei punti sia massima.
Questo è un problema CO, perché il numero di sottoinsiemi possibili è finito, ed in particolare è un problema CO perché le soluzioni sono sottoinsiemi del ground set.
Il ground set, banalmente, è l'insieme dei punti $B\equiv P$, mentre la regione di fattibilità include tutti i sottoinsiemi composti da $k$ punti.
$$X=\left\{x\subseteq B : |x| = k \right\}$$
La funzione oggettiva è la sommatoria di tutte le distanze tra le coppie di punti in $x$:
$$max\underset{x\in X}{f(x)}=\sum_{(i,j):i,j\in x}d_{ij}$$

Per esempio, consideriamo un dataset costituito da $7$ punti e considerando un $k=3$, questo significa che vogliamo trovare
un sottoinsieme costituito da $3$ punti tale che le coppie abbiano distanza massima.

\begin{figure}[H]
    \centering
    \includegraphics[width=3cm]{images/graph_MDP.png}
    \caption{Dataset}
    \label{fig:graph_MDP}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=3cm]{images/sol1_MDP.png}
    \caption{Prima soluzione candidata del MDP}
    \label{fig:cand_sol_MDP}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=3cm]{images/sol_MDP.png}
    \caption{Seconda soluzione candidata del MDP}
    \label{fig:cand_sol_2_MDP}
\end{figure}

La prima soluzione $x'$, considerando una metrica \textit{non fornita} ha come valutazione della funzione oggettiva $f(x')=24$, ed è un sottoinsieme tale per cui
la sua cardinalità sia $\leq k$, e quindi appartenente alla regione di fattibilità $X$.

La seconda soluzione ha come soluzione della funzione oggettiva $f(x'')=46$, questo è anche fattibile visto che $|x''|=k$, ed è una soluzione preferibile alla prima visto che
stiamo cercando il sottoinsieme che soddisfi massimo della funzione oggettiva.

\subsubsection{Interludio 1: la funzione oggettiva}
Fermiamoci un attimo e pensiamo qualcosa a riguardo di questo problema, in particolare soffermiamoci sulla funzione oggettiva.
Questa viene data come funzione che ha come dominio la regione di fattibilità e giunge al
codominio all'insieme dei numeri naturali.
$$f:X\rightarrow \mathbb{N}$$

Il calcolo di questa funzione potrebbe essere molto complesso ed estenuante, ogni singola soluzione ha il proprio valore rispetto alla funzione oggettiva
e si dovrebbe andare a controllare ogni volta in una tabella per svolgere il calcolo, non è una cosa molto interessante da fare.

Questo ovviamente, non è il caso dei precedenti problemi in quanto semplici da svolgere.

In particolare il problema KP una funzione oggettiva \textbf{additiva}, nel calcolare la $f$ dobbiamo effettuare delle somme
con il valore della funzione ausiliaria $\phi$ definita sul ground set, ricordando che nel problema KP, $B \equiv E$.
$$\phi : B\rightarrow \mathbb{N} \text{ induce } f(x)=\sum_{j\in x}\phi_j : X \rightarrow \mathbb{N}$$
Questo è interessante perché significa che si deve memorizzare solamente il valore della funzione ausiliaria $\phi$,
i quali sono $|B|$ valori, e non $2^B$, come sarebbe per i valori della funzione oggettiva che è definita su $X$.

Lo stesso accade per il problema MDP e la sua funzione ausiliaria $d$, anche se quest'ultima ha una funzione oggettiva quadratica,
poi fornito un $n=|B|$ di punti nel caso peggiore si dovranno sommare $\frac{n(n-1)}{2}$ (numero di archi in un grafo completo) distanze, tuttavia però il
calcolo rimane \textit{"solamente"} una somma, quindi avente una \textbf{complessità polinomiale}.
\newline
Nel problema KP una volta che il valore viene fornito per uno specifico sottoinsieme, rimane possibile modificare gli elementi
e ricalcolare il valore della funzione oggettiva facilmente. Il valore della funzione oggettiva nel caso del MDP va trattato in maniera differente
per essere calcolato in tempo lineare (poiché quadratica).

Un'altra importante osservazione è che il problema KP e MDP sono definiti sull'intero insieme delle possibili (non fattibili)
soluzioni $2^B$, e questo è generalmente inutile visto che stiamo cercando
una soluzione fattibile (in alcuni casi questo però sarà utile).

Per riassumere, quando guardiamo un problema cerchiamo di capire come la funzione oggettiva è costituita:
\begin{itemize}
    \item È una funzione additiva?
    \item È una funzione quadratica?
    \item È una funzione semplice da calcolare?
    \item È una funzione semplice da aggiornare?
    \item Su cosa è definita la funzione oggettiva?
\end{itemize}

\subsection{Insieme dei problemi di partizionamento}
In questi problemi un insieme di oggetti viene fornito, l'obiettivo consiste nel dividerlo in sottoinsiemi ottenendo una partizione con alcune peculiarità.
\subsubsection{Bin Packing Problem (BPP)}
Il Bin Packing Problem (BPP), si ha un insieme di oggetti con un \textit{volume}, e si vuole mettere questi oggetti all'interno di
container con una \textit{capacità fissa} (fornita) utilizzando il \textbf{minimo numero di container}.

Dati:
\begin{itemize}
    \item Insieme $E$ di oggetti.
    \item Una funzione $v:E \rightarrow \mathbb{N}$ che fornisce il volume per un dato oggetto $e\in E$.
    \item Un insieme $C$ di containers.
    \item Un numero $V\in \mathbb{N}$ il quale rappresenta la capienza massima dei container (volume massimo contenibile).
\end{itemize}

La prima domanda che ci si vuole porre è: \textit{è un problema di ottimizzazione combinatoria?}

Il ground set è definito come $B=E\times C$, dove ogni elemento di $B$ è definito da una coppia $\langle oggetto, container\rangle$. Una soluzione
per questo problema è un sottoinsieme formato da oggetti di questo tipo, il prodotto cartesiano è necessario poiché si deve selezionare un oggetto ed inserirlo in un determinato container.

Una volta che la lista di coppie contenenti gli elementi di $E$ è costruita, una soluzione candidata sarà ottenuta
(un sottoinsieme del ground set, ma a noi questo non basta, voglia che sia un sottoinsieme della regione di fattibilità).

Consideriamo $B_e$ come il sottoinsieme del ground set dove gli oggetti delle coppie provengono da $E$ (i container sono tutti i possibili), e $B_c$ come il sottoinsieme del ground set dove i container nelle coppie degli elementi provengono da $C$ (gli elementi sono tutti i possibili).
$$B_e=\{(i,j) \in B : i=e\}$$
$$B_c=\{(i,j) \in B : i=c\}$$

La \textbf{regione di fattibilità} include tutte le partizione degli oggetti tra i
container tale per cui non ecceda la capacità di un qualsiasi container.
$$X=\left\{ x\subseteq B : |x\cap B_e|=1\text{ } \forall e \in E, \sum_{(e,c) \in B^c} v(e)\leq V \text{ } \forall c\in C \right\}$$

La prima parte dell'espressione è un vincolo sul sottoinsieme delle soluzioni fattibili $x$, dice che l'intersezione tra il sottoinsieme delle soluzioni fattibili ed il ground set deve avere modulo $1$. Questo significa che gli elementi
all'interno di $x$ devono essere presenti solamente una volta rispetto a gli elementi $E$ del ground set, ovvero $\in B_e$.

La seconda parte dell'espressione anch'essa è un vincolo ma rispetto al volume massimo dei container, dice che la somma dei volumi
di ogni singolo elemento del sottoinsieme fattibile non deve eccedere la capacità massima dei container $V$.

L'obiettivo è quello di minimizzare il numero di container utilizzati:
$$min\underset{x\in X}{f(x)}=|{c \in C : x\cap B^c \neq \emptyset}|$$

Per esempio, consideriamo degli oggetti con diversi volumi e sia data una capacità massima dei container pari a $V=4$.

\begin{figure}[H]
    \centering
    \includegraphics[width=6cm]{images/grap_BPP.png}
    \caption{Dataset}
    \label{fig:grap_BPP}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=2.5cm]{images/sol1_BPP.png}
    \caption{Prima soluzione candidata del Bin Packing Problem}
    \label{fig:sol1_BPP}
\end{figure}

Consideriamo la prima soluzione proposta, visto che la lista dei prodotti cartesiano
rispetta i due vincoli nella definizione della regione
di fattibilità la soluzione $x'$ è una \textbf{soluzione fattibile}.
$$x'=\left\{(a,1),(b,1),(c,2),(d,2),(e,2),(f,3),(g,4),(h,5),(i,5)\right\}\in X$$
$$f(x')=5$$

\begin{figure}[H]
    \centering
    \includegraphics[width=2.5cm]{images/sol2_BPP.png}
    \caption{Seconda soluzione candidata del Bin Packing Problem}
    \label{fig:sol2_BPP}
\end{figure}

Invece, la seconda soluzione proposta è una \textbf{soluzione infattibile}, questo perché gli elementi non stanno
rispettando il secondo vincolo sul volume, e quindi
questo sottoinsieme non è compreso all'interno della regione di fattibilità.
$$x''=\left\{(a,1),(b,1),(c,2),(d,2),(e,2),(f,3),(g,4),(h,1),(i,4)\right\}\notin X$$
$$f(x'')=4$$
Considerando il caso in cui $x''$ fosse una soluzione fattibile avremmo scelto quella tra le soluzioni
proposte, poiché la funzione oggettiva effettua l'ottimizzazione sul minimo.

\subsubsection{Parallel Machine Scheduling Problem (PMSP)}
Il Parallel Machine Scheduling Problem (PMSP), è un problema nel quale un insieme di attività (tasks) deve essere diviso lungo un set di macchine in modo che
il \textit{tempo di completamento} sia minimizzato.

Dati:
\begin{itemize}
    \item Un insieme $T$ di tasks (o \textit{attività}).
    \item Una funzione $d:T \rightarrow \mathbb{N}$ che descrive la lunghezza (temporale) di ogni task.
    \item Un insieme di $M$ macchine.
\end{itemize}

Come prima, il ground set è dato dal prodotto cartesiano di due set forniti:
$$B\equiv T\times M$$
Significa che la soluzione deve essere una coppia $$\langle task,macchina\rangle$$. È importante
sottolineare che la sequenza in cui i task sono eseguiti non è rilevante, invece è rilevante il \textbf{tempo di completamento}
, ovvero il tempo con cui l'ultimo task termina (o il tempo in cui una macchina completa l'esecuzione dei suoi tasks).

La regione di fattibilità include tutte le partizioni delle attività nella macchine:
$$X=\left\{ x\subseteq B : |x\cap B_t|=1 \text{ } \forall t \in T \right\} $$
La \textbf{funzione oggettiva} ha come obiettivo quello di minimizzare il massimo della sommatoria delle lunghezze di tempo per ogni task di ogni macchina:
$$min\underset{x\in X}{f(x)}=max\underset{m\in M}{}\sum_{t:(t,m)\in x} d_t$$

In parole povere, vogliamo trovare il sottoinsieme $x$ che minimizza il tempo di completamento di ciascuna
macchina, dove il tempo di completamento per un singolo task è $\sum_{t:(t,m)\in x} d_t$.
\newline
Per esempio, consideriamo il seguente insieme di dati per tre macchine, $|M|=3$, e sette task differenti $|T|=7$.

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/dataset_PMSP.png}
    \caption{Dataset del Parallel Machine Scheduling Problem}
    \label{fig:dataset_PMSP}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=4cm]{images/sol1_PMSP.png}
    \caption{Prima soluzione Parallel Machine Scheduling Problem}
    \label{fig:sol1_PMSP}
\end{figure}

Consideriamo la prima soluzione proposta:
$$x'=\left\{(T1,M1),(T2,M2),(T3,M2),(T4,M2),(T5,M1),(T6,M3)\right\}\in X$$
$$f(x')=95$$
Possiamo notare che questa è una \textbf{soluzione fattibile},
visto che ogni task accade al meno ed al massimo una volta.
Notiamo che il valore assunto dalla funzione oggettiva è $95$, questo proprio
perché l'ultimo task ha un tempo di completamento pari a $95$.

\begin{figure}[H]
    \centering
    \includegraphics[width=4cm]{images/sol2_PMSP.png}
    \caption{Seconda soluzione Parallel Machine Scheduling Problem}
    \label{fig:sol2_PMSP}
\end{figure}

Consideriamo la seconda soluzione proposta:
$$x''=\left\{(T1,M1),(T2,M1),(T3,M2),(T4,M2),(T5,M2),(T6,M3)\right\}\in X$$
$$f(x'')=120$$
Notiamo che anche questa è una \textbf{soluzione fattibile} visto che ogni task accade al
minimo ed al massimo una volta, in questo casa la funzione oggettiva assume come valore $120$.
Questo significa che fra le due soluzioni proposte la prima è quella \textbf{ottima}.

\subsubsection{Interludio 2: la funzione oggettiva, ancora}
È necessario familiarizzare con il fatto che il ground set $B$ non è sempre uno degli insiemi
forniti nel problema, ma può essere formato dalla combinazione (come il prodotto cartesiano)
di diversi insiemi forniti. Ora affrontiamo la domande proposte nell'ultimo interludio.

\textit{Le funzioni oggettivi di che tipo sono? (additive, quadratiche,...)}
Questa volta le funzioni oggettive per il BPP e PMSP \textbf{non} sono additive, e non sono neanche banali.
È presente un algoritmo polinomiale per calcolare la funzione oggettiva, seppur non complesso,
non è semplice come per i problemi precedenti.

Notiamo che piccole modifiche alle soluzioni hanno un impatto \textit{variabile} sull'obiettivo, per esempio
consideriamo la seconda soluzione $x''$ del PMSP:
\begin{itemize}
    \item Spostare il task $T5$ sulla macchina $M1$, allunga il tempo di completamento complessivo$M1$,
          il risultato della funzione oggettiva cambia perché viene incrementato del task spostato (\textit{\textbf{impatto corrispondente al tempo del task spostato}}).
    \item Spostare il task $T5$ sulla macchina $M3$, non modifica il tempo di completamento complessivo
          delle macchine, il risultato della funzione oggettiva rimane lo stesso (\textit{\textbf{impatto zero}}).
    \item Spostare il task $T2$ sulla macchina $M2$, comporta una modifica dei tempi di completamento
          complessivi, il risultato della funzione oggettiva cambia poiché l'ultimo task viene spostato (\textit{\textbf{impatto intermedio}})

\end{itemize}

In fatti, l'impatto di una modifica di una soluzione dipende :
\begin{itemize}
    \item Da entrambi gli elementi modificati.
    \item E dagli elementi non modificati (questo è contrario alle cose dette nell'interludio 1).
\end{itemize}

Un punto interessante è che la funzione oggettiva del PMSP tende ad essere \textbf{piatta}, ovvero che sono presenti
molteplici soluzioni all'interno del problema dove il valore della funzione rimane lo stesso anche se avvengono
delle modifiche (l'esempio precedente, la soluzione $x''$ rimane fissa per diverse combinazioni su $120$).

\subsection{Problemi delle funzioni logiche}
\subsubsection{The Max-SAT problem}
Il problema del Max-Sat, sia da una formula in \textbf{forma normale congiuntiva}
(CNF, \textit{Conjunctive Normal Form}), si vogliono fornire in ingresso dei valori di
verità alle variabili logiche della CNF tali per cui la formula venga
soddisfatta (valutata come vera).

Dati:
\begin{itemize}
    \item Un insieme $V$ di \textbf{variabili logiche} $x_j$ con valori in $\mathbb{B}\in \{0,1\}$.
    \item Un \textbf{letterale} $l_j(x)\in {x_j,\overline{x}_j}$ che è una funzione che consiste in una variabile logica
          \textit{affermata} o \textit{negata}.
    \item Una \textbf{formula logica} $C_i(x)=l_{i,1} \lor ... \lor l_{i,n_i}$, la quale è
          una disgiunzione o \textit{somma logica} (OR) di letterali. Soddisfare una formula
          logica significa fargli assumere valore 1.
    \item Una formula in \textbf{forma normale congiuntiva} $CNF(x)=C_1\land ... \land C_n$ è una congiunzione di \textit{prodotti logici} di formule logiche.
    \item Una funzione $w$ che provvede dei \textit{pesi} per la formula CNF. La funzione associa ogni formula logica
          della CNF ad un rispettivo peso.
\end{itemize}

Visto che la soluzione consiste in un sottoinsieme caratterizzato dall'assegnamento
di valori di verità a variabili logiche, il \textbf{ground set} sarà il prodotto cartesiano
fra le variabili logiche e l'insieme dei numeri booleani:
$$B=V\times\mathbb{B}=\left\{(x_1,0),(x_1,1),...,(x_n,0),(x_n,1)\right\}$$

La \textbf{regione di fattibilità} è l'insieme delle soluzioni fattibili tali che una \textit{variabile}
venga considerata al più una volta. Essa include tutti sottoinsiemi costituenti
gli assegnamenti semplici che sono:
\begin{itemize}
    \item \textbf{completi}, ovvero che ad ogni variabile corrisponde \textit{almeno} un letterale.
    \item \textbf{consistenti}, ovvero che per ogni variabile corrisponde \textit{al massimo} un letterale.
\end{itemize}

$$X=\left\{x\subseteq B : |x\cap B_v|=1 \text{ }\forall v \in V \right\}$$
$$B_{xj}=\{(x_j,0),(x_j,1)\}$$

La \textbf{funzione oggettiva} (come sempre ottimizzata):
$$max\underset{x\in X}{f(x)}=\sum_{i:C_i(x)=1}w_i$$
L'obiettivo è quello di massimizzare il peso totale della \textit{formula logica soddisfatta}
segnata come $C_i(x)=1 \text{ per } i=1,...,n$ (dove $n$ è il numero di formule logiche presenti).

Consideriamo il seguente esempio:

$$V=\left\{x_1,x_2,x_3,x_4\right\}$$
$$L=\left\{x_1, \overline{x}_1, x_2, \overline{x}_3, x_3,\overline{x}_4, x_4\right\}$$
$$C_1=\overline{x}_1\lor x_2 \text{ ... } C_7=x_2$$
$$CNF = (\overline{x}_1\lor x_2 )\land (\overline{x}_1\lor x_3 )\land (\overline{x}_1\lor \overline{x}_3 )\land (\overline{x}_2\lor x_4 )\land (\overline{x}_2\lor \overline{x}_4 )\land x_1\land x_2$$
$$w_i=1 \forall C_i$$

Consideriamo adesso la seguente soluzione:
$$x=\left\{(x_1,0),(x_2,0),(x_3,1 ),(x_4,1)\right\}$$
La funzione oggettiva per questa soluzione assume valore $f(x)=5$, significa che soddisfa
$5$ formule delle $7$.

\textit{Risulta semplice trovare il valore della funzione oggettiva?} Non proprio, la complessità
della funzione oggettive è polinomiale

In caso di pesi uniformi sono presenti un campo ristretto di valori, che vanno da $0$ a $n$,
il numero di formule logiche, anche se sono presenti $2^|V|$ combinazioni che possono essere considerate.

\subsection{Problemi con matrici numeriche}
\subsubsection{Set covering problem (SCP)}
Data una \textbf{matrice binaria} ed una \textbf{funzione costo} definita per ogni
colonna della matrice (come vettore), si vuole selezionare il sottoinsieme di
colonne che coprono tutte le righe di costo minimo.

Dati:
\begin{itemize}
    \item Matrice binaria $A\in\mathbb{B}^{m,n}$ con insieme delle righe $R$ e insieme delle colonne $C$.
    \item La colonna $j\in C$ copre la riga $i\in R$ quando $a_{ij}=1$.
    \item Una funzione $c:C\rightarrow\mathbb{N}$ provvede il costo di ogni colonna.
\end{itemize}

Il \textbf{ground set} è l'insieme delle colonne.
$$B\equiv C$$
La \textbf{regione di fattibilità} include tutti i sottoinsiemi delle colonne che coprono
tutte le righe.
$$X=\left\{x\subseteq B : \sum_{j\in x}a_{ij}\geq 1 \text{ }\forall i \in R\right\}$$

L'obiettivo è \textit{minimizzare} il costo totale delle colonne selezionate, la \textbf{funzione oggettiva}
è additiva, molto veloce da calcolare ed aggiornare, però la \textit{fattibilità} non è
semplice da ottenere.
$$min\underset{x\in X}{f(x)}=\sum_{j\in x}c_j$$

Consideriamo il seguente esempio di una matrice con il relativo vettore dei costi:

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SCP_datasets.png}
    \caption{Dataset del Set Covering Problem (SCP)}
    \label{fig:dataset_SCP}
\end{figure}
Notiamo che la terza e la quinta riga (iniziando dall'alto) sono coperte dalla prima
colonna. Infatti, \textit{"set covering"}, si coprono i \textit{set} (righe) con
\textit{subset} (colonne).

Consideriamo adesso una prima soluzione proposta:
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SCP_first_sol.png}
    \caption{Prima soluzione proposta del SCP}
    \label{fig:sol1_SCP}
\end{figure}

$$x'={c_1,c_2,c_5 }\in X$$
$$f(x')=19$$
La prima soluzione $x'$ è una \textbf{soluzione fattibile}, perché ogni riga ha almeno un elemento
$a_{ij}\geq 1$.

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SCP_snd_sol.png}
    \caption{Seconda soluzione proposta del SCP}
    \label{fig:sol2_SCP}
\end{figure}

$$x''={c_1,c_5,c_6 }\notin X$$
$$f(x'')=15$$

La seconda soluzione $x''$ \textbf{non è una soluzione fattibile}, dato che la Seconda
riga non è coperta da almeno un elemento delle colonne. Comunque, nel caso in cui
la seconda soluzione sia una soluzione fattibile, allora quest'ultima sarebbe una
soluzione migliore della prima.

\subsubsection{Interludio 3: il test di fattibilità}
Solitamente, gli algoritmi euristici \textbf{richiedono} di risolvere il seguente
problema: \textit{Dato un sottoinsieme $x$, è fattibile o infattibile?}, in breve
$x\in X \text{?}$. Come risolvere questo problema? Innanzitutto, è un \textbf{problema di decisione}.

Consideriamo SCP, la fattibilità può essere decisa passando per ogni riga e sommando gli $1$ che appaiono
nella colonna selezionata: se una qualsiasi riga ha una somma complessiva pari a $0$ la soluzione sarà
\textbf{infattibile}.

Nel caso del KP, il test di fattibilità richiede di calcolare dalla soluzione e testare un singolo numero
(il peso totale rispetto alla capacità dello zaino) proprio come nel MDP, dove la cardinalità della soluzione
si trovava sotto una restrizione $k$.

Altri problemi come il Max-SAT ed il PMSP richiedono di testare la fattibilità su un singolo insieme di
numeri (numero di variabili logiche non si ripeta nella soluzione $x\cap B_v$), mentre problemi come il BPP richiedono di testare su diversi insiemi di numeri (i volumi degli oggetti rispetto
alla capacità dei container).

Alcune modifiche alle soluzioni vengono vietate \textit{a priori} per evitare l'inammissibilità delle soluzioni.
Supponiamo di avere una soluzione fattibile per il MDP, una qualsiasi modifica in cui il numero di punti non è uguale
al numero di punti aggiunti rende la soluzione \textbf{infattibile}.

Alcune modifiche non garantiscono \textbf{inammissibilità} (unfeasible) della soluzione, le quali richiedono un test
\textit{a posteriori} come nel PMSP.

\subsection{Set Packing Problem}
Il Set Packing Problem è un problema molto simile al precedente SCP, questo perché appartiene alla stessa
classe di problemi e provvede un valore per ogni colonna.


Dati:
\begin{itemize}
    \item Una \textbf{matrice binaria} $A\in \mathbb{B}^{m,n}$ con insieme delle righe $R$ e insieme delle colonne $C$.
    \item Sia definito un conflitto tra due colonne $j',j'' \in C$ quando $a_{ij'}=a_{ij''}=1$.
    \item Una funzione $\phi:C\rightarrow \mathbb{N}$ che provvede il valore di ogni colonna.
\end{itemize}
Il \textbf{ground set} è ancora l'insieme delle colonne:
$$B\equiv C$$
La \textbf{regione di fattibilità} include tutti i sottoinsieme di colonne che non sono in conflitto:
$$X=\left\{x\subseteq B:\sum_{j\in x}a_{ij}\leq 1 \text{ } \forall i \in R\right\}$$

L'obiettivo consiste nello scegliere le colonne di valore massimo senza che siano presenti \textit{conflitti}.
$$max\underset{x\in X}{f(x)}=\sum_{j \in x}\phi_j$$

Prendiamo in considerazione la seguente matrice:

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SPP_dataset.png}
    \caption{Dataset Set Packing Problem}
    \label{fig:datasets_SPP}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SPP_first_sol.png}
    \caption{Prima soluzione proposta del SPP (\textit{Set Packing Problem})}
    \label{fig:fst_sol_SPP}
\end{figure}


La prima soluzione proposta è $x'=\left\{c_2,c_4\right\}\in X$, con valutazione della funzione oggettiva
$f(x')=20$. Questa è una soluzione \textbf{fattibile}, visto che non presenti conflitti sulle righe delle colonne
selezionate.

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SPP_snd_sol.png}
    \caption{Seconda soluzione proposta del SPP (\textit{Set Packing Problem})}
    \label{fig:snd_sol_SPP}
\end{figure}
In questo caso \textbf{non è una soluzione fattibile}, visto che avviene il conflitto sulla terza riga, anche quando
la valutazione della funzione oggettiva era meglio della prima soluzione, le somme valutate non sono ottenute dalla
regione di fattibilità $X$.

\subsection{Set Partitioning Problem}
Il problema di Set Partitioning (non lo chiameremo con l'acronimo inglese), è una fusione dei due precedenti problemi
SCP e SPP.

Dati:
\begin{itemize}
    \item Una \textbf{matrice binaria} $A\in \mathbb{B}^{m,n}$ con insieme delle righe $R$ e insieme delle colonne
          $C$.
    \item Una funzione $c:C\rightarrow\mathbb{N}$ che fornisce il costo di ogni colonna.
\end{itemize}
La risoluzione del problema prevede di selezionare il sottoinsieme di \textit{costo minimo} delle colonne
che non sono in conflitto.
Il \textbf{ground set}, anche questa volta, è l'insieme delle colonne:
$$B\equiv C$$
La \textbf{regione di fattibilità} include tutti i sottoinsiemi di colonne che coprono tutte le righe che non
sono in conflitto:
$$X=\left\{x\subseteq C:\sum_{j\in x}a_{ij}=1 \text{ }\forall i \in R\right\}$$
$$min\underset{x\in X}{f(x)}=\sum_{j\in x}c_j$$

Consideriamo la seguente matrice binaria:

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SPP2_dataset.png}
    \caption{Dataset del Set Partitioning Problem}
    \label{fig:dataset_SPP2}
\end{figure}

Ora prendiamo in considerazione la prima soluzione proposta:

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SPP2_fst_sol.png}
    \caption{Prima soluzione del SPP (\textit{Set Partitioning Problem})}
    \label{fig:fst_sol_SPP2}
\end{figure}

$$x'=\left\{c_2,c_3,c_6\right\}\in X$$
$$f(x')=26$$
Notiamo che la soluzione $x'$ è un \textbf{soluzione fattibile}, visto che gli elementi appartenenti alle
selezionati si trovano colonne si trovano in una maniera da non generare conflitti lungo le righe (la sommatoria
degli elementi lungo le righe non porta ad un risultato diverso da $1$).

Ora consideriamo la seconda soluzione candidata:
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/SPP2_snd_sol.png}
    \caption{Seconda soluzione del SPP (\textit{Set Partitioning Problem})}
    \label{fig:snd_sol_SPP2}
\end{figure}

$$x''=\left\{c_1,c_5,c_6\right\}\notin X$$
$$f(x'')=15$$

Anche se il risultato della funzione oggettiva ha un valore migliore (più piccolo) rispetto a quello della
prima soluzione, la soluzione $x''$ \textbf{non è una soluzione fattibile}. Questo perché, gli elementi sulla terza
riga si trovano in conflitto ($\sum_{j\in x}a_{ij}\geq 1$), ed anche perché la seconda riga non viene \textit{coperta}
da alcuna colonna ($\sum_{j\in x}a_{ij}=0$).

\subsection{Interludio 4: ricerca di soluzioni fattibili}
Gli algoritmi euristici spesso richiedono di risolvere un altro problema: \textit{trovare una soluzione
    che fattibile $x\in X$}, questo è un \textbf{problema di ricerca}. Chiaramente dato che le soluzioni
sono definite da una soluzione iniziale, le euristiche di scambio e ricombinazione hanno bisogno di
partire da un sottoinsieme valido tale per cui esso stesso sia una soluzione fattibile.

In base al problema la soluzione può essere banale:
\begin{itemize}
    \item Alcuni insiemi sono sempre fattibili: $x=\emptyset$ (come nel KP, SPP) o $x=B$ (nel SCP).
    \item Alcune soluzioni casuali soddisfano un vincolo come $|x|=k$ (nel MDP).
    \item Alcune soluzioni casuali soddisfano vincoli consistenti, come assegnare un task per ogni macchina
          come nel PMSP, o un valore ad ogni variabile logica come nel Max-SAT.
\end{itemize}
Oppure può essere difficile:
\begin{itemize}
    \item Nel BPP il numero di container deve essere sufficientemente grande.
    \item Nel SPP non è conosciuto alcun algoritmo polinomiale per risolvere il problema.
\end{itemize}

Alcuni algoritmi ingrandiscono al regione di fattibilità da $X$ a $X'$ (processo detto \textit{"rilassamento"}),
la funzione oggettiva $f$ deve essere estesa anch'essa da $X$ a $X'$, ma spesso $X'\setminus X$ provvede delle
soluzioni migliori.

\subsection{Problemi sui grafi}
\subsubsection{Vertex Cover Problem}
Dato un grafo indiretto $G=(V,E)$, selezionare un sottoinsieme di vertici di cardinalità minima tale che ogni
arco del grafo sia incidente a quest'ultimo.

Il \textbf{ground set} è l'insieme dei vertici:
$$B\equiv V$$
La \textbf{regione di fattibilità} include tutti i sottoinsiemi dei vertici tali che gli archi del grafo siano
incidenti ad essi:
$$X=\left\{x\subseteq V:x\cap (i,j)\neq\emptyset \text{ }\forall (i,j)\in E\right\}$$
L'obiettivo è minimizzare il numero di vertici selezionati:
$$min\underset{x\in X}{f(x)}=|x|$$

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/VCP_dataset.png}
    \caption{Dataset del Vertex Covering Problem}
    \label{fig:dataset_VCP}
\end{figure}

Prima soluzione proposta:
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/VCP_sol1.png}
    \caption{Prima soluzione proposta per il VCP}
    \label{fig:fst_sol_VCP}
\end{figure}

$$x'=\left\{ B,D,E,F,G \right\} \in X$$
$$f(x')=5$$
Notiamo che $x'$ è una \textbf{soluzione fattibile}, questo perché il sottoinsieme di vertici selezionato interseca
ogni arco del grafo (appartiene alla regione di fattibilità).

Guardiamo la seconda soluzione proposta:
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/VCP_sol2.png}
    \caption{Seconda soluzione proposta per il VCP}
    \label{fig:snd_sol_VCP}
\end{figure}

Invece, la seconda soluzione \textbf{non è una soluzione fattibile}, anche se la funzione oggettiva porta ad un
risultato che è più convincente della soluzione precedente, questo sottoinsieme non appartiene alla regione di
fattibilità (il sottoinsieme di vertici selezionato non è incidente a tutti gli archi del grafo, e.g.: $(d,e)$).

\subsubsection{Maximum Clique Problem (MCP)}
Dati:
\begin{itemize}
    \item Un \textbf{grafo indiretto} $G=(V,E)$.
    \item Una funzione $w:V\rightarrow \mathbb{N}$ che provvede il peso di ogni vertice.
\end{itemize}
Selezionare il sottoinsieme di coppie di vertici adiacenti di peso massimo. Il \textbf{ground set} è l'insieme
dei vertici.
$$B\equiv V$$

La \textbf{regione di fattibilità} include tutti i sottoinsiemi di coppie di vertici adiacenti.
$$X=\left\{x\subseteq V:(i,v)\in E \text{ }\forall i \in x, \forall j \in x \setminus \{i\}\right\}$$
L'obiettivo è quello di massimizzare il peso dei vertici selezionati:
$$f(x)=\sum_{j\in x}w_j$$

Consideriamo il seguente grafo indiretto costituito da \textbf{pesi uniform} $w_i=1 \forall i\in V$.
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MCP_dataset.png}
    \caption{Dataset per il Maximum Clique Problem}
    \label{fig:MCP_dataset}
\end{figure}
Consideriamo la prima soluzione proposta:
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MCP_sol1.png}
    \caption{Prima soluzione proposta per il MCP}
    \label{fig:MCP_sol1}
\end{figure}
$$x'=\left\{B,C,F,G\right\}\in X$$
$$f(x')=4$$
La prima soluzione proposta è una soluzione \textbf{fattibile}, visto che ogni coppia nel sottoinsieme di vertici
presenta un arco tra di loro.
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MCP_sol2.png}
    \caption{Seconda soluzione proposta per il MCP}
    \label{fig:MCP_sol2}
\end{figure}

$$x'=\left\{A,D,E\right\}\in X$$
$$f(x')=3$$
La seconda soluzione proposta è anch'essa una soluzione \textbf{fattibile}, per lo stesso motivo precedente.

\subsubsection{Maximum Independent Set}
Questo problema è opposto al MCP, vogliamo trovare un sottoinsieme di vertici di peso massimo che non è
connesso da archi.
Dati:
\begin{itemize}
    \item Un \textbf{grafo indiretto} $G=(V,E)$.
    \item Una funzione $w:V\rightarrow \mathbb{N}$ che provvede un peso per ogni arco.
\end{itemize}
Il \textbf{ground set} è l'insieme dei vertici.
$$B\equiv V$$
La \textbf{regione di fattibilità} include tutti i sottoinsiemi di vertici i cui archi \textit{non sono adiacenti}.
$$X=\left\{x\subseteq B : (i,j) \notin E \text{ }\forall i \in x, \forall j \in x\setminus \{i\}\right\}$$
L'obiettivo è quello di massimizzare il peso dei vertici selezionati.
$$max\underset{x\in X}{f(x)}=\sum_{j\in x}w_j$$
Consideriamo il seguente grafo indiretto con \textit{pesi uniformi}.
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MIS_dataset.png}
    \caption{Dataset per il Maximum Independent Set}
    \label{fig:MIS_dataset}
\end{figure}
Adesso consideriamo la prima soluzione proposta:
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MIS_sol1.png}
    \caption{Prima soluzione per il MIS}
    \label{fig:MIS_1}
\end{figure}

$$x'=\left\{B,C,F,G\right\}\in X$$
$$f(x')=4$$
La soluzione $x'$ è una soluzione \textbf{fattibile}, ogni vertice del sottoinsieme proposto \textit{non è connesso}
con un altro vertice dello stesso sottoinsieme.

Consideriamo adesso una seconda proposta:
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MIS_sol2.png}
    \caption{Seconda soluzione per il MIS}
    \label{fig:MIS_2}
\end{figure}

$$x''=\left\{A,D,E\right\}\in X$$
$$f(x'')=3$$
Anche la seconda soluzione è una \textbf{soluzione fattibile}.

\subsubsection{Interludio 5: le relazioni tra i problemi}
Come al solito le domande che uno si dovrebbe porre per un qualsiasi problema sono le solite :
\begin{itemize}
    \item \textit{Come si calcola la funzione oggettiva?}
    \item \textit{Cosa succede se togliamo un vertice?}
    \item \textit{Come si verifica la fattibilità?}
    \item \textit{Cosa succede se aggiungiamo o rimuoviamo un vertice ad una soluzione fattibile?}
\end{itemize}

Questi ultimi tre problemi sui grafi che abbiamo affrontato erano molto simili. Dovrebbe essere già noto
dalla \textbf{teoria delle complessità computazionali} che alcuni problemi possono essere \textbf{ridotti} ad altri
problemi, e che si possa \textit{utilizzare} un problema per risolverne un altro.

Un chiaro esempio è il seguente:
\begin{itemize}
    \item Si parte dall'istanza iniziale del MCP, con un grafo $G=(V,E)$.
    \item Si costruisce il \textbf{grafo complementare} $\overline{G}=(V,(V\times V)\setminus E)$ (un grafo tale
          per cui i vertici adiacenti nel grafo originario ora non lo sono più e viceversa).
    \item Si cerca una soluzione ottima per il MISP su $\overline{G}$.
    \item I vertici corrispondenti danno una soluzione ottimale del MCP su $G$.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{images/interlude5_complementary.png}
    \caption{Una soluzione euristica MISP che da una soluzione euristica MCP}
    \label{fig:interlude_5_graph}
\end{figure}

Questo processo può essere applicato anche nel verso opposto.

Anche i problemi SCP (\textit{Set Covering Problem}) e VCP (\textit{Vertex Covering Problem}) P hanno una relazione tra di loro, ma in maniera differente; ogni istanza del
VCP può essere trasformata in un istanza del SCP.
\begin{itemize}
    \item Ogni arco $i$ corrisponde ad una riga della matrice $A$.
    \item Ogni vertice $j$ corrisponde ad una colonna $A$.
    \item Se l'arco $i$ tocca il vertice $j$, l'insieme $a_{ij}=1$, altrimenti $a_{ij}=0$.
    \item Una soluzione ottimale del SCP da una soluzione ottimale del VCP.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{images/interlude5_vcp_scp.png}
    \caption{Una soluzione euristica SCP che da una soluzione euristica VCP}
    \label{fig:interlude5_vcp_scp}
\end{figure}
In questo caso non è semplice effettuare il procedimento inverso.

I problemi BPP (\textit{Bin Packing Problem}) e PMSP (\textit{Parallel Machine Scheduling Problem})
sono equivalenti, ma in una maniera più sofisticata:
\begin{itemize}
    \item I task corrispondono a gli oggetti.
    \item Le macchine corrispondono ai container, ma ricordiamo che il BPP cerca di ottimizzare il numero di
          container (data una capacità), mentre il PMSP dato un numero di macchine cerca di ottimizzare il \textit{tempo
              di completamento}.
\end{itemize}

Partiamo da un istanza del BPP:
\begin{itemize}
    \item Facciamo un assunzione sul numero di container ottimali, per esempio $3$.
    \item Costruiamo una corrispondente istanza nel PMSP.
    \item Calcoliamo il tempo di completamento ottimale, per esempio $95$; se eccede la capacità,
          incrementa l'assunzione fatta precedentemente (tipo $4$ o $5$). Nel caso contrario, decrementa
          l'assunzione fatta ($2$ o $1$).
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=10cm]{images/interlude5_BPP_scp.png}
    \caption{Una soluzione euristica PMSP che da una soluzione euristica BPP}
    \label{fig:interlude5_PMSP_BPP}
\end{figure}
Il processo inverso è possibile. I due problemi sono equivalenti, ma ognuno dei due deve venire risolto molteplici
volte.

È importante sottolineare il fatto che in caso di \textbf{riducibilità}, una soluzione euristica all'interno di un
istanza ridotta è una soluzione euristica per il problema originale; studiare le relazioni tra i problemi è importante
anche senza pensare agli algoritmi.

\subsubsection{Travelling Salesman Problem (TSP)}
Dato:
\begin{itemize}
    \item Un grafo \textbf{diretto} $G=(N,A)$
    \item Una funzione $c:A\rightarrow\mathbb{N}$ che provvede i costi per ogni arco.
\end{itemize}
Si vuole selezionare un ciclo di costo minimo che visiti tutti i nodi del grafo. Il \textbf{ground set} è l'insieme
degli archi.
$$B\equiv A$$
La \textbf{regione di fattibilità} include i cicli che visitano tutti i nodi del grafo (\textbf{cicli Hamiltoniani}).

L'obiettivo è minimizzare il costo totale degli archi selezionati.
$$min\underset{x\in X}{f(x)}=\sum_{j\in x}c_j$$

\textit{Come determinare quando un sottoinsieme è una soluzione fattibile?} Quel sottoinsieme deve identificare
un ciclo sul grafo ed ogni nodo deve avere esattamente un arco entrante ed uno uscente (ma sempre facente parte
del sottoinsieme). Inoltre, una visita del grafo utilizzando gli archi del sottoinsieme dovrebbe visitare tutti i
nodi, in altre parole non sono previste sotto visite di $G$.

\textit{Cosa accade se si effettua una modifica di una soluzione fattibile?} Questo dipende dal tipo della modifica
effettuata sulla soluzione, potrebbe essere necessario ricalcolare la funzione oggettiva.

\textit{Risulta difficile trovare una soluzione fattibile?} Trovare una soluzione che sia fattibile
potrebbe essere altrettanto difficile; in generale un grafo Hamiltoniano (ovvero che presenta un
ciclo Hamiltoniano) è un problema NP-completo, è di risoluzione banale solo nei grafi \textbf{completi}.

Consideriamo il seguente grafo diretto e pesato:
\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{images/TSP_dataset.png}
    \caption{Dataset per il Travelling Salesman Problem}
    \label{fig:tsp_dataset}
\end{figure}

Consideriamo la prima soluzione proposta:
\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{images/TSP_sol1.png}
    \caption{Prima soluzione del TSP}
    \label{fig:tsp_1_sol}
\end{figure}

$$x'=\left\{(1,4),(4,5),(5,8),(8,7),(7,6),(6,2),(2,3),(3,1)\right\}\in X$$
$$f(x')=102$$
La soluzione $x'$ è una soluzione \textbf{fattibile}.

Consideriamo la seconda soluzione proposta:
\begin{figure}[H]
    \centering
    \includegraphics[width=7cm]{images/TSP_sol2.png}
    \caption{Seconda soluzione del TSP}
    \label{fig:tsp_2_sol}
\end{figure}
$$x''=\left\{(4,5),(5,8),(8,7),(7,4),(1,2),(2,3),(3,6),(6,1)\right\}\notin X$$
$$f(x'')=106$$
La soluzione $x''$ è una soluzione \textbf{fattibile}.

\subsubsection{Minimum Capacitated Spanning Tree Problem (MCSTP)}
Dati:
\begin{itemize}
    \item Un grafo indiretto $G=(V,E)$ con un vertice radice $r\in V$
    \item Una funzione $c:E\rightarrow \mathbb{N}$ che provvede il \textit{costo} di ogni arco.
    \item Una funzione $w:V\rightarrow \mathbb{N}$ che provvede il peso di ogni vertice.
    \item Un numero $W\in \mathbb{N}$ che è la capacità di ogni sotto albero.
\end{itemize}

Si vuole selezionare un \textbf{minimo albero ricoprente} tale che ogni ramo (sotto albero rispetto alla radice)
rispetti la capacità massima $W$. Il \textbf{ground set} è l'insieme degli archi.

$$B\equiv E$$

La \textbf{regione di fattibilità} include tutti gli alberi ricoprenti tali che il peso costituito dai vertici
rispetti la capacità $W$.
L'obiettivo è quello di minimizzare il costo totale degli archi selezionati.

$$min\underset{x\in X}{f(x)}=\sum_{j\in x}c_j$$

Consideriamo il seguente grafo indiretto di pesi uniformi $w_i=1 \forall i\in V$, e con una capacità massima
dei sotto alberi $W=3$.
\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MCSTP_dataset.png}
    \caption{Dataset del Minimum Capacitated Spanning Tree Problem}
    \label{fig:dataset_MCSTP}
\end{figure}

La prima soluzione candidata:

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MCSTP_fst_sol.png}
    \caption{Prima soluzione del MCSTP}
    \label{fig:fst_sol_MCSTP}
\end{figure}

$$x'=\left\{(r,3),(3,2),(3,6),(r,4),(r,5),(5,7),(5,8)\right\}\in X$$
$$f(x')=95$$
Questa è una soluzione \textbf{fattibile}, visto che ogni sotto albero non eccede la
capacità $W$ e i sottoinsiemi sono un minimo albero ricoprente del grafo.

La seconda soluzione candidata:

\begin{figure}[H]
    \centering
    \includegraphics[width=5cm]{images/MCSTP_snd_sol.png}
    \caption{Seconda soluzione del MCSTP}
    \label{fig:snd_sol_MCSTP}
\end{figure}

$$x''=\left\{(r,3),(3,2),(3,6),(r,4),(r,5),(5,7),(5,8)\right\}\notin X$$
$$f(x'')=87$$
Questa \textbf{non è} una soluzione fattibile, visto che il sotto albero destro non rispetta
la capacità massima (nonostante il sottoinsieme sia un albero ricoprente).

Il costo delle operazioni principali cambia, il testi di fattibilità richiede solamente la somma
dei pesi, calcolare la funzione oggettiva richiede risolvere un problema
MST (\textit{Minimum Spanning Tree}).

La funzione oggettiva risulta:
\begin{itemize}
    \item \textbf{Lenta da valutare}, calcolare un MST per ogni sottoinsieme.
    \item \textbf{Lenta da aggiornare}, ricalcolare un MST per ogni sottoinsieme modificato.
\end{itemize}
Se il grafo è \textbf{completo}, i test di ammissibilità sono:
\begin{itemize}
    \item \textbf{Veloci da eseguire}, sommare i pesi dei vertici per ogni sotto albero.
    \item \textbf{Veloci da aggiornare}, sommare i pesi aggiunti e sottrarre quelli rimossi.
\end{itemize}
Visto che la funzione oggettiva è \textbf{additiva}, è abbastanza semplice da valutare, ma mentre
è semplice da ricalcolare, è più difficile verificarne la fattibilità, eccetto per situazioni banali.

Trovare uno \textbf{albero ricoprente capacitato} è un problema fortemente NP-completo, quindi spesso
è difficile trovare una soluzione fattibile a meno che il grafo sia completo. Dato un insieme di vertici,
in ordine si controlla se la soluzione è una soluzione fattibile o meno, è necessario costruire
la corretta rappresentazione dell'albero e poi visitare il sotto albero, sommare i pesi dei vertici, in
una maniera simile ad una visita DFS. \paragraph{Descrizione alternativa}
%Va scritta la descrizione alternativa (secondo o terzo pacco di slide)

\subsubsection{Vehicle Routing Problem (VRP)}
\subsubsection{Interludio 6: combinare rappresentazioni alternative}
Il CMSTP ed il VRP condividono una complicazione interessante: differenti definizioni del
ground set $B$ sono possibili e naturali.
\begin{itemize}
    \item La descrizione come insieme di archi sembra preferibile per gestire la funzione oggettiva.
    \item La descrizione che utilizza un insieme di coppie del tipo
          \newline$(vertice, albero)/(nodo/ciclo)$ sembra migliore per generare
          soluzioni ottime ed ha a che fare con la fattibilità.
\end{itemize}

\noindent\textit{Quale descrizione dovrebbe essere adottata?} Quella che rende più semplice le operazioni più frequenti, oppure una possibilità risulta
quella di utilizzare entrambe le rappresentazioni se le operazioni sono usate molto più frequentemente
che quanto sono aggiornate, in maniera che il fardello di mantenerle aggiornate e consistenti sia accettabile.

Per riassumere, le domande che ci si deve chiedere a riguardo di un problema sono:

\begin{itemize}
    \item Come si calcola la funzione oggettiva?
    \item Come provo che un sottoinsieme sia fattibile?
    \item Come trovo una soluzione fattibile?
    \item Come valutare il test di fattibilità?
    \item Cosa succede quando un cambiamento alla soluzione fattibile viene effettuato: è ancora fattibile?
          Sicuramente non lo è più? È necessario rivalutare da capo la funzione oggettiva o c'è una soluzione migliore?
    \item Quale è la definizione corretta di ground set? Sono qui presenti più definizioni possibili?
    \item Sono presenti relazioni tra questo ed un altro problema?
\end{itemize}

\section{Efficienza teorica}
La seconda parte di questo corso è dedicata alle caratteristiche degli algoritmi euristici: abbiamo precedentemente
descritto gli algoritmi euristici come algoritmi che non provvedono sempre soluzioni corrette, ma che sono
caratterizzati da due aspetti:
\begin{itemize}
    \item Costa molto meno degli algoritmi corretti.
    \item \textit{Spesso} restituisce qualcosa che è \textit{vicino} alla soluzione corretta.
\end{itemize}

Considereremo questi due aspetti, \textbf{costi} e \textbf{qualità}, significa la distanza e la probabilità
di ottenere una certa qualità e considereremo essi da due punti di vista:
\begin{itemize}
    \item \textit{Analisi a priori}, basata sulla teoria.
    \item \textit{Analisi a posteriori}, basata sull'evidenza e sui dati empirici ottenuti dall'esecuzione dell'algoritmo
          su dataset appositi per test.
\end{itemize}

\subsection{Problemi}
Informalmente, un problema è una domanda su un sistema costituito da oggetti matematici. La stessa domanda può
essere spesso posta su diversi sistemi simili.
\begin{itemize}
    \item Un istanza $I\in\mathcal{I}$ consiste in ogni specifico sistema riguardante la domanda.
    \item Una soluzione $S\in\mathcal{S}$ è una risposta corrispondente ad una delle istanze.
\end{itemize}

Per esempio: \textit{$n$ è un numero primo?}, questo è un problema con infinite istanze e due soluzioni.
$$\mathcal{I}=\mathbb{N}^+\setminus{\{1\}}\text{ and }\mathbb{S}=\text{\{yes,no\}}$$

Formalmente, un problema è una funzione che relaziona le istanze e le soluzioni:
$$P:\mathcal{I}\rightarrow\mathcal{S}$$
Definire una funzione non significa sapere come calcolarla.

\subsection{Algoritmi}
Un algoritmo è una \textbf{procedura formale}, composta da passi elementari posti in una sequenza finita, ogni
uno è determinato da un input e dai risultati dei passi precedenti.

Un algoritmo per un problema $P$ è un algoritmo tale per cui un input $I\in\mathcal{I}$ restituisce una soluzione
$S_I\in\mathcal{S}$.
$$A:\mathcal{I}\rightarrow\mathcal{S}$$
Un algoritmo definisce una funzione ed il modo per calcolarla, questo può essere:
\begin{itemize}
    \item \textbf{Esatto}, se la funzione associata coincide con il problema.
    \item Altrimenti \textbf{euristico}.
\end{itemize}
Un algoritmo euristico è utile se risulta:
\begin{itemize}
    \item \textbf{Efficiente}, significa che costa molto meno dell'algoritmo esatto.
    \item \textbf{Efficace}, significa che restituisce frequentemente la soluzione \textit{"vicina"} a quella corretta.
\end{itemize}

\subsection{Costi di un algoritmo euristico}
Il costo di un algoritmo (entrambi i tipi) denotano il costo di computazione durante esecuzione:

\begin{itemize}
    \item \textbf{Tempo}, richiesto per terminare la sequenza finita di passi elementari.
    \item \textbf{Spazio}, quello occupato in memoria dai risultati dei passi precedenti.
\end{itemize}

Il costo in tempo viene molto più discusso perché lo spazio è una risorsa rinnovabile, mentre il tempo non lo è.
Utilizzare lo spazio richiede di utilizzare meno tempo possibile, in oltre è tecnicamente più semplice distribuire
l'utilizzo di spazio che quello del tempo. Lo spazio ed il tempo sono parzialmente intercambiabili,
è possibile ridurre il costo di uno incrementando l'utilizzo dell'altro.

\subsubsection{Il tempo}
Il tempo richiesto per risolvere un problema dipende da diversi aspetti:
\begin{itemize}
    \item L'\textbf{istanza} specifica da risolvere.
    \item L'\textbf{algoritmo} utilizzato.
    \item La \textbf{macchina} che sta eseguendo l'algoritmo.
\end{itemize}
La nostra misura di tempo computazionale dovrebbe essere:
\begin{itemize}
    \item \textbf{Sconnessa} dalla tecnologia, che sia la stessa su macchine differenti.
    \item \textbf{Coincisa}, che viene riassunta in una semplice espressione simbolica.
    \item \textbf{Ordinale}, che sia sufficiente per essere comparata con diversi algoritmi.
\end{itemize}
Il tempo computazionale in secondo per ogni istanza viola tutti i requisiti.

\subsubsection{Complessità asintotica nel caso peggiore}
La complessità asintotica di un algoritmo nel \textbf{caso peggiore} provvede una tale misura
attraverso i seguenti passaggi:
\begin{enumerate}
    \item Definire il tempo come un numero $T$ di operazioni elementari eseguite.
    \item Definire la dimensione di un istanza come opportuno valore di $n$.
    \item Trovare il caso peggiore, ovvero il massimo valore di $T$ su tutte le istanze
          di dimensione $n$. $$T(n)=max\underset{I\in\mathcal{I}_n}{T(I)}\text{  ,  }n\in\mathbb{N}$$
          Ora la complessità in tempo è una funzione $T:\mathbb{N}\rightarrow\mathbb{N}$.
    \item Approssimare $T(n)$ da sotto e/o da sopra con una funzione più semplice $f(n)$, questo
          considerando solamente il loro comportamento asintotico (per $n\rightarrow\infty$).
    \item Collezionare le funzioni in \textbf{classi} con la stessa \textit{funzione di approssimazione}.
\end{enumerate}

\subsubsection{\texorpdfstring{Gli spazi funzionali $\Theta$}{Gli spazi funzionali}}
$$T(n) \in \Theta (f (n))$$
Formalmente significa:
$$\exists c_1, c_2 \in \mathbb{R}^+, n_0 \in \mathbb{N} : c_1 f(n) \leq T(n) \leq c_2 f(n)
    \text{  }\forall n\geq n_0$$

Dove $c_1,c_2$ e $n_0$ sono indipendenti da $n$. $T(n)$ è \textit{"racchiusa"} tra
$c_1 f(n)$ e $c_2 f(n)$, per:

\begin{itemize}
    \item Alcuni \textit{"piccoli"} valori di $c_1$.
    \item Alcuni \textit{"grandi"} valori di $c_2$.
    \item Alcuni \textit{"grandi"} valori di $n_0$.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/theta.png}
    \caption{$f(n)=\Theta(T(n))$}
\end{figure}
Asintoticamente, la funzione $f(n)$ stima la funzione $T(n)$ per un fattore moltiplicativo:
per grandi istanze, il tempo computazionale è al meno ed al più il valore della funzione $f(n)$.

\subsubsection{\texorpdfstring{Gli spazi funzionali $O$}{}}
$$T (n) \in O (f (n))$$
Formalmente significa:
$$\exists c \in \mathbb{R}^+, n_0 \in \mathbb{N} : T(n) \leq c f(n) \text{  }\forall n \geq n_0$$

Dove $c$ e $n_0$ sono indipendenti da $n$. $T(n)$ è \textit{"dominata"} da $c f(n)$, per:
\begin{itemize}
    \item Alcuni \textit{"grandi"} valori di $c$.
    \item Alcuni \textit{"grandi"} valori di $n_0$.
\end{itemize}
Asintoticamente, la funzione $f(n)$ sovrastima la funzione $T(n)$ per un fattore moltiplicativo: per
grandi istanze, il tempo computazionale è al più proporzionale al valore della funzione $f(n)$
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/ogrande.png}
    \caption{$f(n)=O(T(n))$}
\end{figure}

\subsubsection{\texorpdfstring{Gli spazi funzionali $\Omega$}{}}
$$T (n) \in \Omega (f (n))$$
Formalmente significa:
$$\exists c>0, n_0\in\mathbb{N}:T(n)\geq c f(n) \text{  }\forall n\geq n_0$$
Dove $c$ e $n_0$ sono indipendenti da $n$. $T(n)$ \textit{"domina"} $c f(n)$, per:
\begin{itemize}
    \item Alcuni \textit{"grandi"} valori di $c$.
    \item Alcuni \textit{"grandi"} valori di $n_0$.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{images/omega.png}
    \caption{$f(n)=\Omega(T(n))$}
\end{figure}

Asintoticamente, $f(n)$ sovrastima $T(n)$ per un fattore moltiplicativo: per alcune grandi istanze,
il tempo computazionale è almeno proporzionale al valore della funzione $f(n)$.

\subsubsection{L'algoritmo esaustivo}
Per i problemi di ottimizzazione combinatoria la dimensione di un istanza può essere misurata
dalla cardinalità del ground set.
$$n=|B|$$

L'\textbf{algoritmo esaustivo}:
\begin{itemize}
    \item Considera ogni sottoinsieme $x\subseteq B$ tale che $x\in 2^{|B|}$.
    \item Testi la fattibilità (se $x\in X$) in un tempo $\alpha(n)$.
    \item In caso positivo, risolve la funzione oggettiva $f(x)$ in tempo $\beta(n)$.
    \item Se necessario, aggiorna il miglior valore trovato finora.
\end{itemize}

La complessità in tempo degli algoritmi esaustivi è :
$$T(n)\in\Theta\left( 2^n\left(\alpha(n)+\beta(n)\right) \right)$$
Questa risulta lo stesso esponenziale, anche se $\alpha(n)$ e $\beta(n)$ sono dei
polinomi (caso più frequente). La maggior parte delle volte l'algoritmo esaustivo
è \textbf{impraticabile}.

\subsubsection{Complessità polinomiale ed esponenziale}
Nei problemi di ottimizzazione combinatoria, la principale distinzione si trova tra:
\begin{itemize}
    \item \textbf{Complessità polinomiale}, $T(n)\in O(n^d)$, dove $d>0$ è costante.
    \item \textbf{Complessità esponenziale}, $T(n)\in\Omega(d^n)$, dove $d>1$ è costante.
\end{itemize}
Nella prima famiglia fanno parte gli \textbf{algoritmi efficienti}, invece nella seconda
quelli \textbf{inefficienti}. In generale, gli algoritmi euristici sono algoritmi polinomiali
per problemi dove l'algoritmo esatto risulta esponenziale.
\subsubsection{Problemi di trasformazione e riduzione}
Una relazione tra problemi permette la progettazione di algoritmi (\textit{interludio 5}).

Progettare un algoritmo per \textbf{trasformazione}:
\begin{enumerate}
    \item Data un istanza di un problema $P$, detta $I_P$, trasformarla in
          una istanza di un altro problema $Q$, $I_Q$.
    \item Data $I_Q$, applicare l'algoritmo $A_Q$ per ottenere la soluzione $S_Q$.
    \item Data $S_Q$, trasformiamola nella soluzione del problema $P$, $S_P$.
\end{enumerate}

Progettare un algoritmo per \textbf{riduzione}:
\begin{enumerate}
    \item Ripetere le trasformazioni $1,2,3$ diverse volte correggendo $I_Q$ basato sulle soluzioni
          $\{S_Q\}$ già ottenute.
\end{enumerate}

I due algoritmi spesso hanno complessità simili: se $A_Q$ è polinomiale (o esponenziale) e:
\begin{itemize}
    \item Costruire $I_Q$ impiegherà tempo polinomiale/esponenziale.
    \item Il numero di iterazioni sarà polinomiale/esponenziale.
    \item Costruire $S_P$ impiegherà tempo polinomiale/esponenziale.
\end{itemize}

Quindi $A_P$ è un algoritmo \textit{polinomiale/esponenziale}.

Il punto è che se si ha una trasformazione nella quale la modifica dell'istanza è
polinomiale, ed il tempo in cui la trasformazione è applicata è polinomiale, allora la
complessità di tutto l'algoritmo dipenderà dalla complessità di $A_Q$.

\subsubitem{Oltre alla complessità del caso peggiore}
La complessità nel caso peggiore ha diversi svantaggi:
\begin{itemize}
    \item Cancella tutte le informazioni delle istanze più semplici, poiché considera
          solamente le istanza con grandi dimensioni.

    \item Fornisce una approssimativa sovrastima del tempo computazionale, che
          in alcuni rari casi è inutile. Per esempio, i problemi di \textit{programmazione
              lineare}, nei quali i problemi hanno infinite soluzioni ma \textit{finite} soluzioni
          base, ed ammettono un algoritmo che ha complessità esponenziale.

          Tuttavia nella maggioranza dei casi gli algoritmi sono polinomi di bassa complessità.
\end{itemize}
\noindent\textit{Cosa se le istanze difficili sono rare nelle applicazioni pratiche?}
Per compensare, uno può investigare:
\begin{itemize}
    \item La \textbf{complessità parametrizzata}, la quale introduce un nuovo rilevante
          parametro $k$ (che è basato sulla dimensione di $n$), ed esprime il tempo come $T(n,k)$.
    \item La \textbf{complessità nel caso medio}, la quale si assume una probabilità di
          distribuzione su $\mathcal{I}$ ed esprime il tempo come il valore atteso.
          $$T(n)=E[T(I)|I\in \mathcal{I}_n]$$

\end{itemize}

\subsection{Complessità parametrizzata}
L'idea è che alcuni algoritmi non sono esponenziali in $n$ ma sono esponenziali in un
altro parametro $k$ che è più piccolo di $n$.

Se entrambi $k$ e $n$ sono grandi, allora ovviamente l'algoritmo è inefficiente, ma se $k$
è piccolo, allora l'algoritmo sarà efficiente e possibilmente anche polinomiale.

Perciò:
\begin{itemize}
    \item Efficiente su istanze con $k$ piccolo.
    \item Inefficiente su istanze con $k$ grande.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{images/param_coplx.png}
    \caption{Insieme delle istanza infinitamente diviso dai parametri $k$ ed $n$}
\end{figure}

Abbiamo tutti gli insiemi delle istanze del nostro problema, possiamo partizionare queste
istanze con un numero infinito di fette per $n$ e per l'altro parametro $k$. Possiamo
considerare il nostro algoritmo.

Il parametro $k$ può fare parte dell'input come la capacità, il massimo numero di
letterali per formula (SAT), il numero di elementi non-zero (problema matrici numeriche),
il massimo grado o il diametro (problemi con i grafi).

Stranamente il parametro aggiuntivo $k$ può essere parte della soluzione (come la \textit{
    cardinalità} nel VCP): in tale caso non puoi conoscere \textit{a priori} se l'algoritmo
è efficiente o meno, ma solo un approssimazione può essere disponibile. Quindi
se $k$ è facente parte della soluzione, solo \textit{a posteriori} sarà possibile
sapere se si tratta di un algoritmo efficiente.

\subsubsection{Bounded tree search (algoritmo con parametro)}
\noindent\textbf{Per esempio, il VCP}
\newline
L'algoritmo esaustivo: per ogni uno dei $2^n$ sottoinsiemi di vertici, testare se
coprono tutti gli archi, calcolare la cardinalità e mantenere il valore più piccolo.
$$T(n,m)\in\Theta(2^n(m+n)),\text{ dove }n=|V|\text{ e }m=|E|$$

Ma se noi già sappiamo una soluzione con $f(x)=|x|=k+1$, possiamo cercare per una soluzione
di $k$ vertici, e progressivamente decrementare $k$ (o ancora meglio utilizzare
la \textbf{ricerca binaria} su $k$).

L'algoritmo naive: per ogni sotto insieme di $k$ vertici, testare se copre tutti gli archi.
$$T(n,m,k)\in\Theta(n^k m)$$
Per una dato $k$ fissato, l'algoritmo risulta di complessità polinomiale. Detto questo
è possibile fare di meglio.\paragraph{Bounded Tree Search per il VCP}, un algoritmo migliore può
essere basato sulla seguente proprietà:
$$x\cap(u,v)\neq\emptyset\text{ }\forall x\in X,(u,v)\in E$$
Ovvero, una qualsiasi soluzione fattibile include almeno un estremo (vertice)
di ogni arco.

Allora l'algoritmo \textbf{Bounded tree search} (\textit{ricerca delimitata da gli alberi}),
vuole trovare $x$ tale che $x\leq k$:
\begin{enumerate}
    \item Scegliere un qualsiasi arco $(u,v)$, sia che $u\in x$ che $u\notin x$ e
          che $v\in x$ (ovvero che uno degli estremi non faccia per forza parte dalla soluzione).
    \item Per ogni caso \textit{"aperto"}, rimuovere i vertici di $x$ e gli archi che
          essi coprono. $$V:=V\setminus x, E:=E\setminus\{e\in E:e\cap x\neq\emptyset\}$$
    \item Se $|x|\leq k$ e $E=\emptyset$, $x$ è la soluzione richiesta.
    \item Se $|x|=k$ e $E\neq\emptyset$, non è presente alcuna soluzione.
    \item Altrimenti ritorna al passo $1$.
\end{enumerate}
La complessità è $T(n,m,k)\in\Theta(2^km)$, polinomiale in $n$ ($m<n^2$). Per $n>>2$,
questo algoritmo è molto più efficiente di quello \textit{naive}.\newline
\noindent\textbf{Esempio del Bounded tree search}
\newline
Nel seguente grafo con $n=10,m=16$, \textit{è presente una soluzione con $|x|\leq 3$?} (quindi
$k=3$).
\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{images/bounded_tree_search_1.png}
    \caption{Stato iniziale del grafo (\textit{Bounded Tree Search})}
\end{figure}
\noindent Algoritmo esaustivo: $\Theta(2^n(m+n))$, con $2^n(m+n)=1024\cdot(16+10)$\newline
Algoritmo naive: $\Theta(n^k m)$, con $n^k m=1000\cdot 16$\newline
Bounded tree search algorithm: $\Theta(2^km)$ con $2^km=8\cdot 16$

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/bounded_tree_search_2.png}
    \caption{Soluzione del Bounded Tree Search (\textit{ordinamento lessicografico})}
\end{figure}

\subsubsection{Kernelization - "Problem reduction" (algoritmo con parametro)}
La \textit{kernelizzazione} trasforma tutte le istanze di $P$ in istanze più
semplici di $P$, anziché istanze di un altro problema $Q$. Questa pratica è anche
conosciuta con il nome di \textbf{problem reduction} (\textit{riduzione del problema}).

Abbastanza spesso, in fatti, sono presenti delle proprietà molto utili che lo dimostrano:
\begin{itemize}
    \item Esiste una soluzione ottimale che non include certi elementi di $B$ (tali
          elementi possono essere rimossi).
    \item Esiste una soluzione ottimale che include certi elementi di $B$ (tali
          elementi possono essere messi da parte ed aggiunti dopo).
\end{itemize}
In breve rimuove elementi di $B$ senza modificare la soluzione. Possibili risultati
utili sono:
\begin{itemize}
    \item Un algoritmo esatto e polinomiale in $n$ (complessità parametrizzata).
    \item Algoritmi esatti più veloci ed algoritmi euristici.
    \item Migliori soluzioni euristiche.
    \item \textbf{Heuristic kernelization}, applica condizione rilassata sacrificando
          l'ottimalità.
\end{itemize}

\noindent Tornando al problema del VCP, vediamo la \textbf{Kernelization del VCP}:
\newline
Se $\delta_v\geq k+1$, il vertice $v$ appartiene ad una qualsiasi soluzione possibile di
valore $\leq k$. Considerare che $v$ ha $k+1$ archi incidenti e che dovrebbe essere
coperto da altrettanti vertici.
\newline
Algoritmo di kernelizzazione per mantenere solo i vertici della soluzione $x$ con $|x|\leq k$:
\begin{itemize}
    \item Iniziare allo step $t=0$ con $k_0=k$ ed un sottoinsieme di vertici vuoto $x_t:=\emptyset$
    \item Impostare $t=t+1$ ed aggiungere alla soluzione i vertici di grado $\geq k_t+1$.
          $$\delta_v\geq k_t+1\implies x_t := x_{t-1}\cup\{v\}$$
    \item Aggiornare $k_t\text{: } k_t:=k_0-|x_t|$
    \item Rimuovere i vertici con grado zero, quelli di $x$ e degli archi coperti.
          $$V:=\{v\in V : \delta_v > 0\}\setminus x_t$$
          $$E:=\{e\in E : e\cap x_t = \emptyset\}$$
    \item Se $|E|>k_t^2$, non è presente alcuna soluzione fattibile ($k_t$ vertici non sono abbastanza).
    \item Se $|E|\leq k_t^2\implies |V|\leq 2k_t^2$, si applica l'algoritmo esaustivo.
\end{itemize}
La complessità è $T(n,k)\in\Theta(n+m+2^{2k^2}k^2)$.

Per esempio, consideriamo il seguente grafo con $n=10,m=16$, \textit{è presente una
    soluzione con $|x|\leq k_0=5$?}
\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{images/kerneliz_0.png}
    \caption{Grafo d'esempio per la Kernelization del VCP}
\end{figure}

\noindent Algoritmo esaustivo:$\Theta(2^n(m+n))\implies T\approx 2^{10}(10+16)=26624$
\newline
\noindent Algoritmo naive: $\Theta(n^km)\implies T\approx 10^5\cdot 16=16000000$

$\delta_3\geq k_0+1\implies x_1 := \{3\}$ rimozione degli archi incidenti ed avremo $k_1=4$.
\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{images/kerneliz_1.png}
    \caption{Rimozione degli archi incidenti con $k_1=4$}
\end{figure}

$\delta_10\geq k_2+1\implies x_3 := \{5,10\}$ rimozione degli archi incidenti ed avremo $k_3=2$.
\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{images/kerneliz_2.png}
    \caption{Rimozione degli archi incidenti con $k_2=3$}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=1]{images/kerneliz_3.png}
    \caption{Rimozione degli archi incidenti con $k_3=2$}
\end{figure}

\subsection{Complessità nel caso medio (average-case complexity)}
Alcuni algoritmi sono inefficienti solo in un insieme di istanze ridotte, per esempio
il \textit{simplex algorithm} nel caso della programmazione lineare.

Gli studi teorici:
\begin{itemize}
    \item Definiscono un modello probabilistico del problema. Il quale è una
          distribuzione probabilistica su $\mathcal{I}_n\text{ }\forall n\in\mathbb{N}$
    \item Calcolano il valore stimato di $T(I)$
          $$T(n)=E[T(I)|I\in\mathcal{I}_n]$$
\end{itemize}

Gli studi empirici:
\begin{itemize}
    \item Costruiscono un \textit{modello di simulazione} del problema,
          il quale è una distribuzione probabilistica di $\mathcal{I}_n\text{ }\forall n\in\mathbb{N}$
          teorico o empirico (costruito).
    \item Costruire un benchmark di istanze casuali relativo alla distribuzione.
    \item Applicare l'algoritmo e misurare il tempo richiesto.
\end{itemize}

\subsection{Modelli probabilistici per matrici numeriche}
Data una matrice binaria ($m$ righe e $n$ colonne):
\begin{itemize}
    \item \textbf{Equiprobabilità}, elencare tutte le $2^{mn}$ matrici binarie e
          selezionare una delle matrici con probabilità uniforme.
    \item \textbf{Probabilità uniforme}, impostare ogni cella ad $1$ con una data
          probabilità $p$

          $$Pr[a_{ij}=1]=p\text{   }(i=1,...,m;j=1,...,n)$$
          Se $p=0.5$, esso coincide con il modello di equiprobabilità, per un qualsiasi
          altro valore alcune istanze sono più simili di altre.
    \item \textbf{Densità fissa}, estrae $\delta mn$ celle da $mn$ con una
          probabilità uniforme e le imposta ad $1$.
          Se $\delta=p$, esso assomiglierà al modello di probabilità uniforme, ma alcune
          istanze non potranno essere generate.

\end{itemize}

\subsection{Modelli probabilistici per grafi}
Dato un grafo casuale con un numero $n$ di vertici:
\begin{itemize}
    \item \textbf{Equiprobabilità}, elenca tutti i $2^{\frac{n(n-1)}{2}}$ grafi
          e seleziona quello con la probabilità uniforme.
    \item \textbf{Modello di Gilbert} o \textbf{probabilità uniforme} $G(n,p)$
          $$Pr[(i,j)\in E]=p\text{   }(i\in V,j\in V\setminus\{i\})$$
          Tutti i grafi con lo stesso numero di archi $m$ hanno la stessa probabilità
          $p^m(1-p)^{\frac{n(n-1)}{2}-m}$ (diverso per ogni $m$). Se $p=0.5$, esso
          coincide con il modello di equiprobabilità.

    \item \textbf{Modello di Erdos-Renyi} $G(n,m)$: estrae $m$ coppie di
          vertici non ordinate su $\frac{n(n-1)}{2}$ con probabilità uniforme e
          crea un arco per ognuna. Se $p=\frac{2m}{n(n-1)=p}$, esso assomiglierà
          al modello con probabilità uniforme, ma alcune istanze non verranno generate.
\end{itemize}

\subsection{Modelli probabilistici per funzioni logiche}
Considerando una CNF casuale con un dato numero di variabili $n$:
\begin{itemize}
    \item \textbf{Insieme con probabilità fissa}: elenca tutte le
          $\binom{n}{k}2^k$ formule con $k$ letterali distinti e consistenti, ed
          aggiungo ognuno alla CNF con probabilità $p$.
    \item \textbf{Insieme con dimensione fissa}: costruisco $m$ formule,
          aggiungo ad ognuna $k$ letterali distinti e consistenti, estratti con
          probabilità uniforme. Se $p=\frac{m}{\binom{n}{k}2^k}$, esso assomiglierà
          al modello con probabilità fissa, ma alcune istanze non potranno essere generate.
\end{itemize}

\subsection{Transizione di fase}
Differenti valori (deterministici o probabilistici) dei parametri corrispondono
a diverse regioni dell'insieme delle istanze.

Per i grafi:
\begin{itemize}
    \item $m=0$ e $p=0$ corrisponde al grafo vuoto.
    \item $m=\frac{n(n-1)}{2}$ e $p=1$ corrisponde al grafo completo.
    \item Valori intermedi corrispondono al grafo di densità intermedia (
          deterministicamente per $m$, probabilisticamente per $p$).
\end{itemize}

Per molti problemi la \textbf{performance} dell'algoritmo è decisamente differente
in regioni diverse, riguardo a:
\begin{itemize}
    \item \textbf{Tempo computazionale} (per algoritmi esatti ed euristici).
    \item \textbf{Qualità della soluzione} (per algoritmi euristici).
\end{itemize}

Spesso, la \textit{variazione} di performance avviene all'improvviso in piccole
regioni dello spazio dei parametri, come la \textit{transizione di fase} all'interno
di un sistema fisico.

Questo è utile per predire il comportamento di un algoritmo data un istanza.
\subsection{Transizione di fare per 3-SAT e Max-3-SAT}
Data una CNF di $n$ variabili e con formule logiche contenenti $3$ letterali.

\begin{itemize}
    \item 3-SAT: \textit{è qui presente un assegnamento di verità che soddisfi tutte le formule ?}
    \item Max-3-SAT: \textit{quale è il massimo numero di formule soddisfacibili?}
\end{itemize}

Con l'aumentare del rateo formule-variabili $\alpha=\frac{m}{n}$:
\begin{itemize}
    \item Le istanze soddisfacibili decrementano da quasi tutte (tante variabili
          per poche formule) a quasi nessuna (poche variabili per tante formule).
    \item Il tempo di calcolo per il 3-SAT incrementa fortemente e poi subito
          decresce, invece nel Max-SAT incrementa ulteriormente dopo la transizione.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.52]{images/max_sat_SAT.png}
    \caption{Plot delle fasi}
\end{figure}

Per $n\rightarrow\infty$ la transizione si concentra attorno $\alpha_c\approx 4.26$
\subsection{La transizione di fase per il VCP}
Il VCP esibisce una transizione di fase simile alla precedente quando $\frac{|x|}{|V|}$
incrementa.
\begin{itemize}
    \item Il tempo computazionale prima esplode, dopo cade.
    \item Per $n\rightarrow\infty$ la transizione si concentra attorno al valore critico.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{images/phase_VCP.png}
    \caption{Fase del VCP}
\end{figure}

Quando $\frac{|x|}{|V|}$ è piccolo, alcuni vertici sono chiaramente necessari, problema risolto.
Quando $\frac{|x|}{|V|}$ è grande, molti vertici sono chiaramente necessari, problema risolto.

\subsection{Costo computazionale degli algoritmi euristici}
La complessità in tempo di un algoritmo euristico è solitamente:
\begin{itemize}
    \item \textbf{Strettamente polinomiale} (con esponenti bassi).
    \item \textbf{Abbastanza robusta} rispetto ai parametri secondari.
\end{itemize}
Perciò, la stima nel caso peggiore è buona nella media dei casi.
Le \textbf{metaeuristiche} utilizzano passi casuali o memoria:
\begin{itemize}
    \item La complessità è ben definita per componenti singoli dell'algoritmo.
    \item La complessità globale non è chiaramente definita, in teoria potrebbe
          essere estesa \textit{indefinitamente}, in pratica, è definita da una
          condizione imposta dall'utente.
\end{itemize}

\noindent\textit{Perché discutere ciò in un corso di algoritmi euristici ?}
\begin{itemize}
    \item Per guidare la ricerca dell'algoritmo corretto, un algoritmo corretto
          può essere efficiente in un caso specifico, ed inefficiente in un caso peggiore.
    \item Per mostrare che gli algoritmi euristici possono interagire proficuamente:
          poiché gli algoritmi euristici provvedono informazioni per migliorare gli algoritmi
          esatti (rendendoli più efficienti).
    \item Per mostrare che la kernelization migliora gli algoritmi euristici (diventano più efficienti
          ed efficaci).
    \item Per identificare \textit{a priori} le istanze più ardue, certamente non tutti
          gli algoritmi hanno le stesse istanze \textit{"complesse"}.
\end{itemize}

\section{Efficacia teorica}
\subsection{Efficacia di un algoritmo euristico}
Un algoritmo euristico è utile se è:
\begin{itemize}
    \item \textbf{Efficiente}, ovvero \textit{"costa"} molto meno di un algoritmo esatto.
    \item \textbf{Efficace}, ovvero restituisce \textit{"frequentemente"} una soluzione
          che è vicina a quella esatta.
\end{itemize}

Adesso vogliamo discute dell'efficacia degli algoritmi euristici, possiamo formalmente discutere
questo concetto introducendo il concetto di distanza di una soluzione rispetto ad una ottimale e la
frequenza (probabilistica) di ottenere una soluzione ottimale o quasi (rispetto ad una data distanza)
rispetto ad una soluzione ottima.
Queste caratteristiche possono essere combinate in una distribuzione a frequenza di soluzioni
più o meno vicine alla soluzione ottimale (andrà introdotto un concetto di distanza).

L'efficacia di un algoritmo euristico può essere investigata in due modi:
\begin{itemize}
    \item \textbf{Analisi teorica} (\textit{a priori}), provando che un algoritmo trova
          sempre o con una data frequenza soluzioni con una certa garanzia di qualità.
    \item \textbf{Analisi sperimentale} (\textit{a posteriori}), misurando le prestazioni dell'algoritmo
          su istanze di benchmark campionate per dimostrarne la presenza.
\end{itemize}

\subsection{Distanza tra le soluzioni}
Come detto precedentemente, dobbiamo dare un significato al concetto di distanza, e possiamo fornire
molteplici interpretazioni differenti.\\L'efficacia di un algoritmo di ottimizzazione euristico $A$
è misurata dalla \textbf{differenza} tra il valore $f_A(I)$ (la funzione oggettiva sull'istanza
$I$ calcolata da $A$) e il valore ottimale $f*(I)$ (la soluzione migliore per l'istanza $I$).

\subsubsection{Differenza assoluta}
Una possibile definizione iniziale tra due valori:
$$\widetilde{\delta}_A(I)=|f_A(I)-f^{*}(I)|$$
Seppure questa definizione è molto naturale ed ovvia, è raramente utilizzata in pratica poiché dipende
dall'unità di misura della funzione oggettiva: basa pensare di provare a minimizzare il tempo complessivo
nel caso del TSP e che lo si misuri in giorni. Si potrebbe provare ad utilizzare ore, minuti o secondi
anziché ed il valore di $\widetilde{\delta}_A(I)$ dipenderà fortemente da questa scelta. Questo sarà
valido quando la funzione oggettiva è un numero puro.

\subsubsection{Differenza relativa}
La seconda definizione è basata sull'idea che calcolare la differenza relativa rispetto alla soluzione
ottimale.
$$\delta_A(I)=\frac{|f_A(I)-f^*(I)|}{f^*(I)}$$
Questo è un approccio molto frequente nell'analisi sperimentale ed il suo vantaggio è che nel caso in
cui la funzione oggettiva abbia un unità di misura, allora il rapporto (\textit{rateo}) ottenuto sarà
un numero \textit{puro}.

\subsubsection{Rapporto di approssimazione}
Un terzo approccio, ampiamente utilizzato, è il rapporto di approssimazione:
$$\rho_A(I)=max\left[\frac{f_A(I)}{f^*(I)},\frac{f^*(I)}{f_A(I)}\right]\geq 1$$
Il quale include sia il problema di minimizzazione che di massimizzazione: nel caso in cui sia un
problema di minimizzazione, probabilmente $f*(I)<f_A(I)$ e viceversa per i problemi di massimizzazione.
Chiaramente è collegato alla differenza relazionale, in fatti nel caso dei problemi di minimizzazione:
$$\delta_A(I)=\rho_A(I)-1$$
La relazione esiste anche per i problemi di massimizzazione.

\subsection{Analisi teorica: garanzia di approssimazione}
Per garantire \textit{a priori} le prestazioni dell'algoritmo, l'idea è ancora una volta quella
di considerare il caso peggiore, proprio come per l'efficienza. In generale quando si applica
un algoritmo euristico il risultato $f_A(I)$ potrebbe essere un pessimo (distante) risultato
rispetto alla soluzione ottimale $f*(I)$, ma se l'algoritmo è buono la differenza non sarà
molto grande;

La differenza tra $f_A(I)$ e $f^*(I)$ è generalmente illimitata, ma per alcuni algoritmi è limitata:
\begin{itemize}
    \item \textbf{Approssimazione assoluta}: $$\exists\widetilde{\alpha}_A\in\mathbb{N}:\widetilde{\delta}_A(I)\leq\widetilde{\alpha}\text{ }\forall I\in\mathcal{I}$$
          Significa che la la distanza assoluta rispetto alla soluzione ottimale è limitata da
          un intero costante; un esempio è l'algoritmo di Vizing per la colorazione del grafo ($\widetilde{\alpha}=1$).

    \item \textbf{Approssimazione relativa}: $$\exists\alpha_A\in\mathbb{R}^+:\rho_A(I)\leq\alpha_A\text{ }\forall I\in\mathcal{I}$$
          Significa che il rapporto di approssimazione $\rho_A(I)$ ha un limite superiore delimitato da una costante reale $\alpha_A$.
          La cosa interessante è che la definizione può essere estesa a casi in cui una garanzia di approssimazione
          costante non può essere trovata considerando l'approssimazione come un valore ma come un'apposita funzione
          parametrizzata rispetto alla dimensione dell'istanza:
          $$\rho_A(I)\leq\alpha_A(n)\text{ }\forall I\in\mathcal{I}_n,n\in\mathbb{N}$$
\end{itemize}
In conclusione, è importante sottolineare che mentre l'efficienza e è necessariamente
dipendente dalla dimensione dell'istanza, l'efficacia \textit{potrebbe} non esserlo.

\subsubsection{Come ottenere una garanzia di approssimazione?}
Fornite le basi teoriche, ora possiamo descrivere in maniera generale un metodo per introdurre e
dimostrare un algoritmo con garanzia di approssimazione.\\ Per i problemi di minimizzazione,
si vuole dimostrare:
$$\exists\alpha_A\in\mathbb{R}:f_A(I)\leq\alpha_A f^*(I)\text{ }\forall I\in\mathcal{I}$$

Uno schema generalmente astratto è:
\begin{itemize}
    \item Trovare un modo per costruire una sottostima $LB(I)$ $$LB(I)\leq f^*(I)\text{,   }I\in\mathcal{I}$$
    \item Trovare un modo per costruire una sovrastima $UB(I)$ che sia in relazione con il coefficiente $\alpha_A$
          $$UB(I)=\alpha_A LB(I)\text{,   }I\in\mathcal{I}$$
    \item Trovare un algoritmo $A$ la cui soluzione non sia peggiore di $UB(I)$ $$f_A(I)\leq UB(I)\text{   }I\in\mathcal{I}$$
\end{itemize}

Se i tre passi sono stati completati e vengono trovati valori ed algoritmi adatti
$$f_A(I)\leq UB(I)=\alpha LB(I)\leq\alpha f^*(I)\text{   }\forall I\in\mathcal{I}\implies f_A(I)\leq\alpha_A f^*(I)\text{   }\forall I\in\mathcal{I}$$

La parte più complicata potrebbe essere il secondo passo, quindi affrontiamo mostrando un esempio.
\paragraph{Garanzia di approssimazione per il VCP: algoritmo 2-approssimato}: dato un grafo indiretto
$G=(V,E)$ trovare un sottoinsieme di vertici di cardinalità minima tale per cui ogni arco dell'arco
del grafo sia incidente.\\Definiamo:
\begin{itemize}
    \item Un insieme \textbf{"matching"}, tale per cui sia l'insieme degli archi non adiacenti.
    \item Un insieme \textbf{"maximal matching"}, è un insieme di tipo \textit{matching} tale che
          ogni altro arco del grafo è adiacente ad uno dei suoi archi.
\end{itemize}
Algoritmo di Matching:
\begin{enumerate}
    \item Costruire un \textit{maximal matching} $M\subseteq E$ scorrendo gli archi di $E$ e includendo in
          $M$ quelli che non sono adiacenti ad $M$ (ora ogni arco di $E\setminus M$ è adiacente ad un arco di $M$).
    \item L'insieme di vertici \textit{estremi} degli archi in \textit{matching} è la soluzione del VCP
          $$x_A := \bigcup_{(u,v)\in M}\{u,v\}$$ Può essere migliorata rimuovendo i vertici ridondanti.
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/matching_0.png}
    \caption{Algoritmo di Matching - Passo 0 (stato iniziale del grafo)}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/matching_1.png}
    \caption{Algoritmo di Matching - Passo 1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/matching_2.png}
    \caption{Algoritmo di Matching - Passo 2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/matching_3.png}
    \caption{Algoritmo di Matching - Passo 3}
\end{figure}

Torniamo adesso alla garanzia di approssimazione. Un possibile limite inferiore è quello di includere nella soluzione
solamente uno dei vertici dell'arco nel \textit{maximal matching}: considero solo gli archi nel \textit{maximal
    matching} $M$.

È chiaro che il grafo consiste nei soli archi $e\in M$ ($G'=(V,M)$) solo \textit{metà} dei vertici inclusi nella
soluzione $x_A$ copre gli archi in $M$. In altre parole, la copertura ottimale dei vertici degli archi in $M$
è certamente più piccola della copertura ottimale di tutti gli archi in $E$.

Per fornire un esempio numerico, supponiamo che un certo grafo per il VCP abbia la soluzione ottimale $f^*=5$
(quindi $5$ vertici possono coprire tutti gli archi) e che l'algoritmo di matching trovi il matching massimale
con $3$ archi, quindi la soluzione dell'algoritmo sarà $f_A=2\cdot|M|=6$. Però coprire tutti gli archi in $M$
(considerare questo insieme come un grafo), basteranno $\frac{|M|}{2}=3$ vertici!

Il valore $\frac{|M|}{2}$ è un possibile limite inferiore (o \textit{lower bound}) per il nostro problema VCP:
$$LB(I)=\frac{|M|}{2}\leq f^*(I)$$
Ma c'è dell'altro: sappiamo che $x_A$ viene calcolato prima che sia una soluzione attualmente fattibile ed
è collegata a $LB(I)$:
$$f_A=2\cdot |M|=2\cdot LB(I)=UB(I)$$
Quindi abbiamo trovato sia il limite inferiore che quello superiore. Adesso forniamo una dimostrazione
formale che l'algoritmo di matching è \textbf{2-approssimato}:
\paragraph{Dimostrazione algoritmo di Matching 2-approssimato}, per prima cosa dimostriamo che la cardinalità
dell'insieme "matching" sia una sottostima $LB(I)$: la cardinalità di una copertura ottimale per un qualsiasi
sottoinsieme di archi $E'\subseteq E$ non supera quella di una copertura ottimale per $E$
$$|x^*_{E'}|\leq|x^*_E|$$
e la copertura ottimale di un qualsiasi insieme di matching $M$ ha cardinalità $\frac{|M|}{2}$, quindi
$$|M|\leq|E|\implies |x^*_M|\leq |x^*_E|\implies\frac{|M|}{2}\leq |x^*_E|\text{   }\forall M$$
$$LB(I)=\frac{|M|}{2}\leq |x^*_e|\text{ è un limite inferiore valido}$$
In parole, visto che l'insieme $M$ ha una cardinalità minore o uguale a quella di $E$, la soluzione ottimale
(la quale ha cardinalità esatta di $\frac{|M|}{2}$) ha una cardinalità minore o uguale a quella della
soluzione ottimale per l'insieme $E$, rendendola un valido limite inferiore.

Il fatto che $|M|$ stesso consiste in una sovrastima è provato dal fatto che la definizione dei vertici degli
archi in $M$ copre tutti gli archi in $E$, significa che l'insieme dei vertici $M$ consiste in una soluzione
fattibile (il che significa che è un limite superiore ed è un valore ottimale) e copre sia il "matching" che
gli archi adiacenti. Perciò $|M|=UB(I)=2\cdot LB(I)$ è una sovrastima.

La prova si conclude con il fatto che l'algoritmo restituisce soluzioni di valore $f_A(I)\leq UB(I)$, visto che
in $M$ potrebbero essere presenti dei vertici \textit{ridondanti} che possono essere rimossi. Questo
implica che $f_A(I)\leq 2\cdot f^*(I)\text{   }\forall I\in\mathcal{I}$, che è $\alpha_A=2$
\paragraph{Lo stretto legame tra stime inferiori e superiori}, \textit{sono presenti delle istanze $\overline{I}$ per
    il VCP tali che $f_A(\overline{I})=2\cdot f^{*}(\overline{I})$ utilizzando l'algoritmo di Matching?} Più
in generale, sono presenti delle istanze $\overline{I}$ tali che:
$$f_A(\overline{I})=\alpha_A f^*(\overline{I})$$
e se così, \textit{come sono le istanze $\overline{I}$?} In altre parole, dopo aver dimostrato che $f_A(I)$ è
in relazione con $f^*(I)$ attraverso $\alpha_A$, questo è \textbf{costante}, \textbf{preciso} e \textbf{importante}
o e \textit{"solo"} un limite superiore? Lo studio delle istanze $\overline{I}$ è utile per valutare se sono
rare o frequenti e per introdurre modifiche \textit{ad hoc} per migliorare l'algoritmo.
\paragraph{Garanzia di approssimazione per il TSP (disuguaglianza triangolare)}, consideriamo il TSP
con delle assunzione aggiuntive, ovvero che $G=(N,A)$ sia \textbf{completo} e che la funzione $c$ sia
simmetrica e soddisfi la \textbf{disuguaglianza triangolare}:
$$c_{ij}=c_{ij}\text{   }\forall i,j\in\mathbb{N}$$
e che
$$c_{ij}+c_{jk}\geq\text{   }\forall i,j,k\in\mathbb{N}$$
Il problema in generale, è fortemente NP-completo. Ma è anche fortemente NP-completo capire se le istanze
hanno una soluzione fattibile (non quale sia fattibile), ovvero se è presente un ciclo Hamiltoniano che visiti
tutti i nodi.

Sotto le precedenti assunzioni un algoritmo euristico può essere costruito con una garanzia di approssimazione
associata ad esso.
\paragraph{Algoritmo Double-tree}
\begin{enumerate}
    \item Considera il grafo completo e indiretto $G$
    \item Costruisci un minimo albero ricoprente $T^*=(N,X^*)$
    \item Fai una visita in pre-ordine di $T^*$ e costruisci due liste di archi:
          \begin{enumerate}
              \item $x$ sarà la lista degli archi utilizzata sia per la visita che per il backtracking:
                    questo è un ciclo che visita ogni nodo, possibilmente molteplici volte.
              \item $x'$ sarà la lista degli archi che connettono i nodi in pre-ordine con il primo nodo:
                    questo è un ciclo che visita ogni nodo esattamente una volta.
          \end{enumerate}
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{images/TSP_double_tree_0.png}
    \caption{Double-tree per TSP - Passo 1 (grafo completo con archi omessi)}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{images/TSP_double_tree_1.png}
    \caption{Double-tree per TSP - Passo 2 (\textit{Minimo Albero Ricoprente} $T^*$)}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{images/TSP_double_tree_2.png}
    \caption{Double-tree per TSP - Passo 3.a (costruzione $x$)}
\end{figure}
$$x=\{
    A,C,F,H,\textcolor{blue}{F},I,\textcolor{blue}{F},\textcolor{blue}{C},
    D,G,L,\textcolor{blue}{G},E,\textcolor{blue}{G},
    \textcolor{blue}{D},B,\textcolor{blue}{D},\textcolor{blue}{C},A
    \}$$

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{images/TSP_double_tree_3.png}
    \caption{Double-tree per TSP - Passo 3.b (costruzione $x'$)}
\end{figure}

$$x'=\{A,C,F,H,U,D,G,L,E,B,A\}$$

La struttura è la stessa del VCP: una sottostima è trovata assieme al fattore di moltiplicazione
per costruire un limite superiore e quindi è provato che un algoritmo euristico può essere
dominato da questo limite superiore, il che significa che l'algoritmo euristico
è quasi sicuramente un fattore moltiplicato per la soluzione ottima. Andiamo a dimostrare
che l'algoritmo double-tree è 2-approssimato.
\paragraph{Dimostrazione algoritmo Double-tree 2-approssimato},
Rimuovendo un arco da un ciclo Hamiltoniano restituisce un percorso Hamiltoniano,
il quale è necessariamente più economico. Visto che un cammino Hamiltoniano ricopre tutti
i nodi, è effettivamente un albero ricoprente, e solitamente non di costo minimo. Quindi,
un attuale minimo albero ricoprente è sicuramente un limite inferiore sul costo di un
ciclo Hamiltoniano. La serie di nodi della visita DFS del MST (\textit{Minimum Spanning Tree})
assieme con i suoi archi di back tracking genera un ciclo Hamiltoniano nel grafo originale,
poiché è presente una coppia di archi diretti per ogni nodo (quindi ogni arco visitato nella
DFS esiste nel grafo originale).

Il costo di questo ciclo Hamiltoniano è necessariamente una sovrastima, visto che il
costo di tutti percorsi nel grafo rispetta la disuguaglianza triangolare; mentre la visita
restituisce, per esempio il percorso $A\rightarrow B\rightarrow C$, il grafo rispetta l'
uguaglianza triangolare scegliendo l'arco $A\rightarrow C$ la soluzione sarà di costo minimo.
Quindi, visto che $LB(I)$ è uguale al costo del MST ed il ciclo ha esattamente il doppio
degli archi del MST, abbiamo $UB(I)=2\cdot LB(I)$.

L'euristica è dominata da un limite superiore ed un qualsiasi circuito $x$ ha:
$$f_A(I)\leq UB(I)\leq 2\cdot LB(I)\leq 2\cdot f^*(I) \text{   }\forall I\in \mathcal{I}$$

\subsection{Inapprossimabilità}
Per un problema \textbf{inaprossimabile}, tutti gli algoritmi approssimati sono esatti, quindi
alcuni problemi non possono essere approssimati a meno che alcune proprietà della
complessità computazionale vengano verifica, cosa che è molto difficile che accada.

Per esempio, consideriamo la seguente famiglia di istanze del TSP che violano la
disuguaglianza triangolare nella seguente maniera:

\[c_{ij}=\begin{cases}
        0 & \forall (i,j)\in A_0\subset A   \\
        1 & \forall (i,j)\in A\setminus A_0
    \end{cases}
\]

ed il grafo è completo. Se una qualsiasi funzione di costo nullo ($f^*(I)=0$) viene trovata, significa che la
soluzione contiene solo archi in $A_0$ che compongono il ciclo Hamiltoniano. Quindi, in un senso, è presente
un grafo non-completo $G(N,A_0)$ che ha un ciclo Hamiltoniano come soluzione fattibile, tale che è lo stesso
per quello del grafo originale (questo significa che il grafo originale è il \textit{completamento} del nuovo
grafo).
Questo è bello finché una soluzione per il grafo completo viene trovata con costo nullo, allora potrai
veramente risolvere il problema del TSP nella forma decisionale anche sul grafo non completo, il quale
è un problema fortemente NP-completo. Quest non può essere fatto esattamente, a meno che $P=NP$, il
che è difficile. La funzione oggettiva di una qualsiasi istanza $\overline{I}$ è:
\[\begin{cases}
        f^*(\overline{I})=0     & \text{Se }A_0\text{ contiene un ciclo Hamiltoniano} \\
        f^*(\overline{I})\geq 1 & \text{Altrimenti}
    \end{cases}
\]

Non possiamo trovare una garanzia di approssimazione sul valore $\alpha$ per un algoritmo
polinomiale tale che:
$$f_A(I)\leq\alpha f^*(I)\text{  }\forall I\in\mathcal{I}$$
Poiché assumendo che sia possibile quello che accade è che se il grafo avesse un ciclo Hamiltoniano
di costo zero, allora necessariamente l'algoritmo di approssimazione restituirà un costo:
$$f^*(\overline{I})=0\Leftrightarrow f_A(\overline{I})=0$$
in parole povere, l'algoritmo di approssimazione risolve la versione decisionale del TSP nel
caso di un istanza con il grafo non-completo, questo è possibile risolvendo un problema
fortemente NP-completo in tempo polinomiale e dimostrando che $P=NP$. Visto che questo è molto
difficile che sia così, il problema il TSP è considerato un problema inaprossimabile.

\subsection{Schemi di approssimazione}
A volte è possibile trovare qualcosa meglio di una semplice approssimazione: per un qualsiasi
problema difficile è presente un algoritmo esaustivo che fornisce la migliore approssimazione
possibile garantendo $\alpha_A=1$ (in quanto esatto), ciò richiede tempo esponenziale $T_A$.

Gli algoritmi approssimati solitamente una garanzia di approssimazione peggiore ($\alpha_A >1$)
ma essi potrebbero richiedere tempo polinomiale $T_A$.

Ora nel mezzo di questi due casi si possono trovare molte cose, significa che al posto di un singolo algoritmo
polinomiale con tempo $T_A$ e garanzia $\alpha_A$ potrebbe essere presente una completa
famiglia di \textit{"differenti compromessi"} tra efficienza ed efficacia, che incrementano la
complessità computazionale e migliorano la garanzia di approssimazione.

\begin{itemize}
    \item Migliori e migliori garanzie di approssimazione: $\alpha_{A_1} > ... > \alpha_{A_r}$
    \item Peggiori e peggiori complessità computazionali: $T_{A_1}<...<T_{A_r}$
\end{itemize}

Tali famiglie di algoritmi sono chiamate \textbf{schemi di approssimazione}, i quali sono algoritmi
parametrici $A_\alpha$, che permettono di scegliere $\alpha$. Un esempio di questo è il problema KP.

\subsection{Oltre al caso peggiore}
Proprio come per l'efficienza, l'efficacia ha dei metodi di misurazione che sono approcci
differenti dal \textit{caso peggiore}. Potresti avere un brutto caso peggiore senza approssimazione
o un approssimazione $\alpha=1000000$ che restituisce una soluzione ottimale. Sono presenti differenti approcci.

\subsubsection{Parametrizzazione}
Anziché dividere le istanze per la dimensione, altri parametri $k_i$ possono essere identificati in maniera che
essi possano provvedere una garanzia di approssimazione che dipenda da $k_i$ e non sia costante.

\subsubsection{Caso medio}
Assume una probabilità di distribuzione sulle istanze e ne calcola il fattore di approssimazione desiderato (
l'algoritmo potrebbe avere delle brutte prestazioni solo su rare istanze).

\subsubsection{Randomizzazione}
Le operazioni dell'algoritmo dipendono non solo dall'istanza, ma anche dai numeri pseudocasuali, in maniera
che la soluzione diventa una variabile casuale la quale possa essere investigata (la complessità in tempo
potrebbe anch'essa essere casuale, ma solitamente non lo è).

Per un algoritmo casuale $A$, vengono considerate come variabili casuali $f_A(I)$ e $\rho_A(I)$. Un
\textbf{algoritmo di approssimazione casuale} ha un rapporto di approssimazione il cui valore desiderato
è limitato da una costante:
$$E[\rho_A(I)]\leq\alpha_A\text{  }\forall I\in\mathcal{I}$$

Considerando il problema Max-SAT: data una CNF, si vuole trovare l'assegnamento di verità per le variabili logiche
tale che soddisfi un sottoinsieme di peso massimo di formule.

Allora una algoritmo puramente casuale assegna ad ogni variabile $x_j(j=1,...,n)$:
\begin{itemize}
    \item Un valore $False$ con probabilità 0.5
    \item Un valore $True$ con probabilità 0.5
\end{itemize}

\paragraph{Approssimazione casuale per il Max-SAT} Sia $C_X\subseteq\{1,...,m\}$ il sottoinsieme
di formule soddisfatte dalla soluzione $x$. Il valore oggettivo $f(x)=f_A(I)$ è il peso totale
delle formule in $C_x$ ed il valore desiderato è:
$$E[f_A(I)]=E\left[\sum_{i\in \mathcal{C}_x}w_i\right] = \sum_{i\in \mathcal{C}}(w_i\cdot Pr[i\in \mathcal{C}_x])$$
Sia $k_i$ il numero di letterali della formula $i\in \mathcal{C}$ e $k_min = min\underset{i\in \mathcal{C}}{k_i}$

$$Pr[i\in \mathcal{C}_x]=1-\left(\frac{1}{2}\right)^{k_i}\geq 1-\left(\frac{1}{2}\right)^{k_{min}}\text{  }\forall i\in \mathcal{C}$$
$$\implies E[f_A(I)]\geq\sum_{i\in \mathcal{C}}w_i\cdot\left[1-\left(\frac{1}{2}\right)^{k_min}\right]=\left[1-\left(\frac{1}{2}\right)^{k_{min}}\right]\sum_{i\in \mathcal{C}}w_i$$
e visto che $E[\rho_A(I)]=f^*(I)/E[f_A(I)]$ e $f^*(I)\leq\sum_{i\in \mathcal{C}w_i}\text{  }\forall I\in\mathcal{I}$
uno ottiene:
$$E[\rho_A(I)]\leq 1/\left[1-\left(\frac{1}{2}\right)^{k_{min}}\right]\leq 2$$

\section{Valutazione empirica delle prestazioni}
Dopo la considerazione di un analisi algoritmica svolta \textit{a priori}, la quale consiste
nel dimostrare la presenza di alcune garanzie su alcuni aspetti dell'algoritmo che
sono stati studiati come il costo computazione della qualità delle soluzioni, ora
è possibile considerare l'analisi algoritmica \textit{a posteriori}.

Questo perché l'analisi a priori è complicata su diversi aspetti: nell'analisi dell'efficienza
il concetto è semplice mentre nell'analisi della qualità è molto più complicata,
poiché i "passi elementari" degli algoritmi non hanno una relazione diretta
con la qualità della soluzione. Inoltre, nel caso medio e della randomizzazione si richiede
un trattamento statistico.

L'analisi teorica può esser una pratica \textbf{insoddisfacente} quando le conclusioni sono basate
su \textbf{assunzioni non rappresentative}, come: un caso peggiore non frequente (molto difficile e
su istanze molto rare), oppure una distribuzione probabilistica delle istanze irrealistica.

\subsection{Analisi sperimentale}
Il metodo sperimentale è l'approccio tipico che viene utilizzato nella scienza con l'eccezione
della matematica, la quale è basata più su approcci formali, ma gli algoritmi sono l'eccezione
all'eccezione, visto che solo alcune proprietà legate alle prestazioni degli algoritmi possono
essere dimostrate e informazioni interessanti possono essere estrapolate dalle prestazioni pratiche.

Quindi abbiamo trovato un \textit{isola empirica} in un mare di formalismo.

L'approccio empirico consiste nell'osservare la realtà ed effettuare alcune assunzioni su come
la realtà "funzioni", questo formulando un \textbf{modello}. Dopo, una sequenza di passi
viene ripetuta fino ad ottenere un \textbf{modello soddisfacente}:

\begin{enumerate}
    \item Progettare esperimenti computazionali per validare il modello.
    \item Eseguire gli esperimenti e collezionare i risultati.
    \item Analizzare i risultati con metodi quantitativi.
    \item Revisionare il modello in base ai risultati ottenuti.
\end{enumerate}

\subsubsection{Modello}
\textit{Che cosa è un modello nel contesto dell'algoritmica?} In fisica un modello è una
legge che regola il comportamento di un fenomeno e, come analogia, nell'algoritmica
un modello è una legge che ipoteticamente regola il comportamento dell'algoritmo stesso.

Le leggi possono essere del tipo: assumere che la complessità computazionale
dell'algoritmo sia lineare, questo dipenderà da altri parametri come il massimo
grado divertici del grafo, ecc...

Questo è qualcosa che viene assunto basato sulla conoscenza dell'algoritmo ma anche su
un \textit{trend} esposto dall'approccio empirico.

L'analisi sperimentale degli algoritmi mira:
\begin{enumerate}
    \item Ottenere indici di efficienza ed efficacia compatti di un algoritmo.
    \item Paragonare gli indici di algoritmi differenti per ordinarli.
    \item Descrivere la relazione tra gli indici ed i valori parametrici delle istanze.
    \item Suggerire miglioramenti negli algoritmi.
\end{enumerate}

\subsubsection{Benchmark}
Visto che non tutte le istanze possono essere testate, viene definito un campione di
riferimento (\textbf{benchmark sample}): un campione significativo deve rappresentare differenti
\begin{itemize}
    \item Dimensioni, in particolare per l'analisi dei costi computazionali.
    \item Caratteristiche strutturale (\textit{densità, grado, diametro, ...}).
    \item Tipi
          \begin{itemize}
              \item di applicazione: logistici, telecomunicazioni, produzione, ...
              \item di generazione: realistici, artificiali, trasformazioni di altri problemi, ...
              \item di distribuzione probabilistica: uniforme, normale, esponenziale, ...
          \end{itemize}
\end{itemize}
Cercare un benchmark sample che sia "equiprobabile" non è significativo perché:
\begin{itemize}
    \item Le istanze di un insieme sono infinite.
    \item Gli insiemi infiniti non ammettono l'equiprobabilità (grande domanda della statistica).
\end{itemize}

Al contrario, noi possiamo:
\begin{itemize}
    \item Definire classi finite di istanze che sono:
          \begin{itemize}
              \item Sufficientemente difficile per essere istruttive.
              \item Sufficientemente frequenti in applicazione di interesse.
              \item Veloci abbastanza nella risoluzione, in modo da fornire dati sufficienti per le conclusioni.
          \end{itemize}
    \item Estrarre benchmark samples da queste classi.
\end{itemize}

\paragraph{Riproducibilità}\mbox{}\\
Il metodo scientifico richiede risultati riproducibili e controllabili. Quindi,
se vengono fatte delle indagini, è necessario assicurarsi che altre persone siano
in grado di replicare l'esperimento. Quindi, è necessario utilizzare \textbf{istanze
    pubblicamente disponibili} (o renderle pubblicamente disponibili), specificare i
dettagli di implementazione, il linguaggio di programmazione e il compilatore
dell'algoritmo implementato e i valori ambientali come la macchina utilizzata,
il sistema operativo e la memoria disponibile.

\subsection{Confronto di algoritmi euristici}
Un algoritmo euristico è migliore di un altro altro quando simultaneamente
\begin{itemize}
    \item Ottiene risultati migliori.
    \item Richiede meno tempo.
\end{itemize}
Algoritmi lenti con buoni risultati ed algoritmi veloci con brutti risultati
non possono essere paragonati in una maniera significativa. In alcune situazioni
specifiche il tempo computazionale può essere trascurato, precisamente quando
non si vuole fare alcun confronto ma si cerca di fare solo una stima e anche
quando si sa che i l tempo di calcolo è più o meno lo stesso (per conosciuti
motivi strutturali, ad es. due algoritmi uguali ma con qualche differenza nei
parametri).

\subsubsection{Descrivere le prestazioni di un algoritmo}
Per descrivere le prestazioni di un algoritmo un \textbf{metodo statistico} può essere
fornito. In particolare, l'idea è quella di modellare un algoritmo come se fosse un
esperimento casuale in cui i risultati dipendono dalla scelta di un oggetto
all'interno dello \textit{spazio di campionamento} (sample space), definito come
il campionamento delle istanze
$$\overline{\mathcal{I}}\subset \mathcal{I}$$
Il tempo computazionale $T_A(I)$ assieme alla differenza relativa $\delta_A(I)$
sono entrambe \textit{variabili casuali}.

Le proprietà statistiche delle variabili casuali $T_A(I)$ e $\delta_A(I)$ descrivono
le prestazioni dell'algoritmo $A$.

Quello che viene effettuato: anzichè considerare tutti i possibili valori del tempo
computazionale e tutti i possibili valori della differenza relativa, si descrivono
le variabili casuali con le loro proprietà statistiche, cosa che darà una descrizione
statistica delle prestazioni dell'algoritmo.

\subsection{Valutazione a posteriori dell'efficienza}
\subsubsection{Analisi del tempo computazionale (\textit{RTD diagram})}
Il diagramma \textit{"Run Time Distribution"} (RTD) è il grafico della funzione di
distribuzione $T_A(I)$ su $\overline{\mathcal{I}}$.
$$F_{T_A}(t)=Pr[T_A(I)\leq t]\text{  }\forall t\in\mathbb{R}$$
Visto che $T_A(I)$ dipende fortemente dalla dimensione di $n(I)$, significa che
diagrammi RTD significativi solitamente si riferiscono a benchmarks
$\overline{\mathcal{I}}_n$ con un $n$ fissato (e possibilmente fissati anche
altri parametri suggeriti dall'analisi del caso peggiore).
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.35]{images/RTD_0.png}
    \caption{Diagramma \textit{Run Time Distribution}}
\end{figure}

Se tutti i parametri influenti vengono identificati e fissati, il diagramma RTD degenera
in una funzione a scala (ovvero, tutte le istanze richiedono lo stesso tempo).
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{images/RTD_stairs.png}
    \caption{RTD degenerato ina una \textit{step function}}
\end{figure}
Il diagramma RTD è:
\begin{itemize}
    \item \textbf{monotona non decrescente}, più istanze vengono risolte in più tempo.
    \item \textbf{graduale e continua verso destra}, il grafico aumento ad ogni $T(I)$.
    \item \textbf{uguale a $0$ per $t<0$}, nessuna istanza è risolta in tempo negativo.
    \item \textbf{uguale ad $1$ per $t\geq\underset{I\in\overline{\mathcal{I}}}{T(I)}$}, tutti vengono risolti con il tempo più grande.
\end{itemize}
Per benchmark sample, il disegno sembra continuo, ma non lo è.

Costruzione del RTD:
\begin{itemize}
    \item Eseguire l'algoritmo su ogni istanza $I\in\overline{\mathcal{I}}$
    \item Costruire l'insieme $T_A(\overline{\mathcal{I}})=\{T_A(I):I\in\overline{\mathcal{I}}\}$
    \item Ordinare $T_A(\overline{\mathcal{I}})$ non decrementando i valori $t_1 \leq ...\leq t_{|\overline{\mathcal{I}}|}$
    \item Disegnare i punti $\left(t_j,\frac{j}{|\overline{\mathcal{I}}|}\right)$ per $j=1,...,|\overline{\mathcal{I}}|$ ed
          i segmenti orizzontali (chiusi a sinistra, aperti a destra).
\end{itemize}

\subsubsection{Analisi del tempo computazionale (\textit{scaling diagram})}
Lo \textbf{scaling diagram} descrive la dipendenza di $T(I)$ sulla dimensione di $n(I)$
\begin{itemize}
    \item Genera una sequenza di valori di $n$ ed un campion $\overline{\mathcal{I}}_n$
          per ogni valore.
    \item Applica l'algoritmo ad ogni $I\in\overline{\mathcal{I}}_n\text{  }\forall n$
    \item Disegna tutti i punti $(n(I),T(I))$ o i punti medi $\left(n,\frac{\sum_{I\in\overline{\mathcal{I}}_n}T(I)}{|\overline{\mathcal{I}}_n|}\right)$
    \item Assumere una \textbf{funzione interpolante}.
    \item Stimare i parametri numerici della funzione interpolante.
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{images/interp_funct.png}
    \caption{Stima dei parametri rispetto alla funzione interpolante}
\end{figure}
L'analisi fornisce empiricamente un caso medio di complessità, con fattori di molteplicità
ben determinati (anziché $c_1$ e $c_2$), e non più grande del caso peggiore.

\subsubsection{Interpolazione dello \textit{scaling diagram}}
La famiglia corretta di funzioni interpolanti può essere suggerita, da:
\begin{itemize}
    \item Analisi teorica
    \item Manipolazione dei grafici
\end{itemize}
Solitamente l'\textbf{interpolazione lineare} è lo strumento corretto.
Il dragamma di scaling si trasofrma in una linea dritta quando
\begin{itemize}
    \item Un algoritmo esponenziale è rappresentato da una \textbf{scala semi logaritmica} (il logaritmo
          viene applicato solo sull'asse del tempo).
          $$\log_2 T(n)=\alpha n + \beta \Leftrightarrow T(n)=2^\beta(2^\alpha)^n$$

    \item Un algoritmo polinomiale è rappresentato da una scala logaritmica (il logaritmo viene
          applicato su entrambi gli assi).
          $$\log_2 T(n) = \alpha log_2 n + \beta \Leftrightarrow T(n) = 2^\beta n^\alpha$$
\end{itemize}

\subsection{Valutazione a posteriori dell'efficacia}
\subsubsection{Analisi della qualità della soluzione (\textit{SQD diagram})}
Il diagramma \textbf{Solution Quality Distribution} (SQD) è il grafico della funzione di distribuzione $\delta_A(I)$ su
$\overline{\mathcal{I}}$
$$F_{\delta_A}(\alpha) = Pr[\delta_A (I)\leq\alpha]\text{   }\forall\alpha\in\mathbb{R}$$
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{images/SQD_0.png}
    \caption{Diagramma \textit{Solution Quality Distribution}}
\end{figure}
Per un qualsiasi algoritmo, la funzione di distribuzione di $\delta_A(I)$
\begin{itemize}
    \item \textbf{Monotona non decrescente}: più casi vengono risolti con lacune peggiori.
    \item \textbf{graduale e continua a destra}: il grafo effettua un passo ad ogni $\delta(I)$
    \item \textbf{Uguale a $0$ per $\alpha <0$}: nessuna istanza viene risolta con lacune peggiori.
    \item \textbf{Uguale ad $1$ per} $\alpha\geq\underset{I\in\overline{\mathcal{I}}}{max}\delta_I$: tutte le istanze sono risolte all'interno della lacuna peggiore.
\end{itemize}

Se $A$ è un:
\begin{itemize}
    \item Algoritmo esatto, è una funzione a scala, uguale ad $1\text{   }\forall\alpha\geq0$
    \item Algoritmo $\overline{\alpha}$-approssimato, è una funzione uguale ad $1\text{   }\forall\alpha\geq\overline{\alpha}$
\end{itemize}
\paragraph{Costruzione del diagramma}
\begin{itemize}
    \item Eseguire l'algoritmo $\forall I\in\overline{\mathcal{I}}$
    \item Costruire l'insieme $\delta_A(\ovcal{I})=\{\delta_A(I):I\in\ovcal{I}\}$
    \item Ordinare $\delta_A(\ovcal{I})$ per valori non decrescenti : $\delta_1,...,\delta_{\ovcal{I}}$
    \item Disegnare i punti $\left(\delta_j,\frac{j}{|\ovcal{I}|}\right)$ per $j=1,...,|\ovcal{I}|$ ed
          i segmenti orizzontali (chiusi a sinistra, aperti a destra).
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.45]{images/SQD_1.png}
\end{figure}

\subsubsection{Diagrammi SQD parametrici}
Dati i problemi teorici e pratici per costruire un campione significativo, il diagramma è parametrizzato
rispetto a:
\begin{itemize}
    \item Un parametro descrittivo delle istanze (dimensione, densità, ...)
    \item Un parametro di distribuzione probabilistica assunto per le istanze (varianza dei costi, ...)
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.45]{images/SQD_2.png}
\end{figure}

Le conclusioni sono più limitate, ma il campione è più significativo, i \textbf{trend generali} possono
essere evidenziati.

\subsubsection{Confronto tra algoritmi utilizzando SQDs}
\textit{Come determinare quando un algoritmo è migliore di un altro?}
\begin{itemize}
    \item \textbf{Dominanza stretta}, ottiene migliori risultati su tutte le istanze.
          $$\delta_{A_2}(I)\leq\delta_{A_1}(I)\text{   }\forall I\in\mathcal{I}$$
    \item \textbf{Dominanza probabilistica}, la funzione di distribuzione ha valori più alti per
          tutti i valori di $\alpha$.
          $$F_{\delta_{A_2}}(\alpha)\geq F_{\delta_{A_1}}(\alpha)\text{   }\forall\alpha\in\mathbb{R}$$
\end{itemize}
Il seguente grafico non mostra alcuna dominanza, ma $A_1$ è meno \textit{"robusto"} di $A_2$, i
risultati di $A_1$ sono più spari di $A_2$.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{images/SQD_3.png}
\end{figure}

\subsection{Descrizione statistica compatta}
Tutte le precedenti descrizioni prendono molto e sarebbe meglio avere dei numeri o una descrizione
compatta delle prestazioni di un algoritmo: come un indice statistico riguardante la differenza
relativa rispetto alla soluzione ottima. Questo coinvolge indici statistici classici di:
\begin{itemize}
    \item posizione, come il \textbf{sample mean} (\textit{mean} si riferisce alla media aritmetica di tutti
          i valori).
          $$\overline{\delta}_A = \frac{\sum_{I\in\ovcal{I}}\delta_A (I)}{|\ovcal{I}|}$$
    \item dispersione, come il \textbf{sample variance}.
          $$\overline{\sigma}^2_A = \frac{\sum_{I\in\ovcal{I}}(\delta_A(I)-\overline{\delta}_A)^2}{|\ovcal{I}|}$$

\end{itemize}
Questi indici tendono ad essere molto influenzati dai \textbf{valori anormali} (\textit{outliers}). Per
esempio, un algoritmo che $9/10$ fornisce la soluzione ottima ed $1/10$ fornisce dieci volte la
soluzione ottima, presenta chiaramente un valore anormale (questo non va bene). Utilizzando l'indice
"sample mean" avverrà la somma delle differenze $\frac{0+0+...+9}{10}=0.9$ restituendo un divario
medio del $90\%$, il quale non è una buona rappresentazione.

Altri indici statistici sono più \textit{"stabili"} e dettagliati:
\begin{itemize}
    \item \textbf{sample median}
    \item \textbf{sample quantiles}
\end{itemize}

\subsubsection{Boxplots}
Sia il sample median che il quantiles possono essere rappresentati utilizzando una rappresentazione
grafica chiamata \textbf{boxplot} (o diagramma a \textit{"scatola e baffi"} o \textit{"box and whiskers plot}).

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/boxplot.png}
    \caption{Esempio di boxplot}
\end{figure}
Supponiamo di avere 20 istanze nelle quali la relativa differenza spazia da $\approx4\%$ a $\approx11.5\%$,
rispettivamente nel caso migliore e nel caso peggiore.
All'interno del diagramma sono presenti cinque valori:
\begin{itemize}
    \item \textbf{sample median} (\textit{mediana}).
    \item \textbf{lower and upper sample quartiles} (\textit{quartile minore e superiore}, rispetto alla mediana).
    \item \textbf{extreme sample values}, (\textit{valori estremi}, escludendo gli \textit{outliers}).
\end{itemize}

La \textbf{mediana} è il valore che si trova oltre
metà delle istanze e sotto metà delle istanze: se il campione è costituito da un numero dispari di casi
la mediana è il valore dell'elemento nel "mezzo", nel nostro caso la mediana è qualcosa tra la decima
e l'undicesima istanza (un'altra opzione è quella di utilizzare proprio la decima istanza).

I quantili (considerando i \textit{quartili}) tipici utilizzati in un boxplot sono il
\textbf{primo ed il terzo}, cioè i valori che separano un quarto dell'osservazione dall'altra
di tre quarti; Per esempio su $20$ elementi il primo quartile corrisponde al quinto elemento
mentre il terzo al quindicesimo.

Una volta trovati i primi tre valori sono necessari altri due valori che sono i campioni estremi,
essi corrispondono al \textit{minimo ed al massimo}.

Questo è un diagramma interessante che fornisce sia la posizione che la dispersione del benchmark,
detto questo esattamente metà delle istanze cadrà nella "scatola" e le rimanenti tra la fine
della scatola ed i baffi. Questo diagramma è una descrizione semplificata del SQD e, visto che due
algoritmi possono essere paragonati utilizzando l'SQD, essi possono essere paragonati altrettanto
utilizzando i relativi boxplot.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/boxplot_comparison.png}
    \caption{Confronto tra algoritmi attraverso i boxplot}
\end{figure}
Chiaramente, come mostrato in figure, il confronto è meno preciso di un diagramma SQD e meno
informazioni possono essere estratte, tuttavia delle interessanti conclusioni possono essere fatte.
In primis, prendendo sempre come esempio la figura sovrastante, gli $8$ boxplot rappresentano la
\textit{differenza relativa} su un campione fisso di un benchmark, dove i cerchi sono gli outliers.

Se paragoniamo $A_7$ e $A_8$, i due boxplot sono completamente separati, questo significa che tutte
le istanze dell'algoritmo $A_7$ hanno valori migliori, questa è la definizione di \textbf{dominanza stretta}.

Invece, si parla di \textbf{dominanza probabilistica} quando ognuno dei $4$ quartili di un boxplot
si trova sotto l'altro boxplot con cui ci si sta confrontando, come per esempio tra $A_2$ e $A_3$,
ma questa \textbf{non è una condizione sufficiente} (solo necessaria). Sempre considerando lo
stesso esempio potrebbe essere che un istanza parti dal baffo inferiore di $A_2$ e tutte le altre
si trovino esattamente nel primo quartile mentre accade l'opposto per $A_3$: in questo caso sicuramente
non può essere considerata la dominanza probabilistica.

\subsubsection{Relazione tra qualità e tempo computazioanle}
Un algoritmo euristico è migliore di un altro non quando restituisce risultati migliori ma quando
viene eseguito in un tempo minore. Se questo non accade, non si può dire che uno domini l'altro.

Tuttavia, sono presenti molto algoritmi che non trovano una singola soluzione come gli algoritmi
classici, ma quello che attuano è migliorare le soluzioni precedentemente trovate. Questo ne
consegue in terminazioni premature.

In particolare gli algoritmi con \textit{metaeuristiche} (passi casuali o meccanismi mnemonici)
hanno un tempo computazione $t$ fissato dall'utente e potenzialmente illimitato.
Sia $\delta_A(t,I)$:
\begin{itemize}
    \item La differenza relativa ottenuta da $A$ al tempo $t$ sull'istanza $I$.
    \item $+\infty$ se $A$ non ha ancora trovato una soluzione fattibile nel tempo $t$.
\end{itemize}
Come funzione del tempo di calcolo $t$, $\delta_A(t,I)$ è:
\begin{itemize}
    \item \textbf{monotona a scala non-crescente}.
    \item \textbf{costante dopo la terminazione regolare} $t\geq T(I)$ (se esiste).
\end{itemize}
\paragraph{Algoritmi randomizzati}\mbox{}\\
Se gli algoritmi metaeuristici hanno passi casuali, allora la differenza relativa è funzione del
seme casuale (\textit{random seed}) $\omega\in\Omega$ rendendo $\delta_A(t,I,\omega)$. Quando si effettua
il testing di un tale algoritmo, dovrebbe essere preso in considerazione che sono presenti due
elementi casuali: l'istanza $I$ estratta da $\ovcal{I}$ ed il random seed.

Durante il test questi parametri possono essere combinati o distinti, significa che in un esperimento
$I$ può essere fissato and un gruppo di semi $\overline{\Omega}$ viene testato, o al contrario, $\omega$
è fisso ed un campione di istanze $\ovcal{I}$ viene testato. I risultati su $\omega$ sono solitamente
riassunti fornendo entrambe la differenza minima $\delta_A^*(t,I)$ ed il tempo totale $|\overline{\Omega}|t$,
oppure la differenza media relativa $\overline{\delta}_A(t,I)$ ed il singolo tempo d'esecuzione $t$.

\subsubsection{Classificazione}
Ora abbiamo tutti gli elementi per fornire una \textbf{classificazione} abbastanza complicata per
algoritmi euristici, esatti ed approssimati. Questa vuole essere una classificazione di tutti
i tipi di algoritmi per problemi di ottimizzazione combinatoria

La relazione tra la qualità della soluzione e tempo computazionale permette di classificare gli
algoritmi in:
\begin{itemize}
    \item \textbf{completi}: per ogni istanza $I\in\mathcal{I}$, si trova l'ottimo in un tempo finito (un
          nome diverso per gli \textit{algoritmi esatti}).
          $$\exists\overline{t}_I\in\mathbb{R}^+ :\delta_A(I,t)=0 \text{  }\forall t\geq\overline{t}_I,I\in\mathcal{I}$$

    \item \textbf{probabilisticamente ed approssimativamente completi} (\textit{probabilistically approximately}):
          per ogni istanza $I\in\mathcal{I}$, si trova l'ottimo con una probabilità convergente ad $1$, rispetto
          ad una differenza relativa uguale a $0$, per $t\rightarrow\infty$
          (molti algoritmi metaeuristici randomizzati). Questi algoritmi non forniscono una soluzione ottima in un
          tempo finito, ma lo faranno se verrà fornito \textit{abbastanza tempo}.
          $$\lim_{t\rightarrow +\infty}Pr[\delta_A(I,t)=0]=1\text{  }\forall I\in\mathcal{I}$$

    \item \textbf{essenzialmente incompleti}: per alcune istanze di $I\in\mathcal{I}$, si trova
          la soluzione ottima con una probabilità strettamente $<1$ per $t\rightarrow +\infty$ (la maggior
          parte sono algoritmi greedy, algoritmi di ricerca locale, ...). Questi sono i "veri" algoritmi
          euristici.
          $$\exists I\in\mathcal{I}:\lim_{t\rightarrow +\infty}Pr[\delta_A(I,t)=0]<1$$
\end{itemize}

\paragraph{Classificazione generalizzata}\mbox{}\\
Un ovvia generalizzazione sostituisce la ricerca per l'ottimo con un dato livello di approssimazione:
$$\delta_A(I,t)=0\rightarrow\delta_A(I,t)\leq\alpha$$

\begin{itemize}
    \item \textbf{algoritmi $\alpha$-completi}: per ogni istanza $I\in\mathcal{I}$, trovano una soluzione $\alpha$-approssimata
          in un tempo finito (questi essenzialmente è una descrizione formale per gli algoritmi $\alpha$-approssimati).

    \item \textbf{algoritmi probabilisticamente ed approssimativamente $\alpha$-completi}: per ogni istanza $I\in\mathcal{I}$,
          trovare una soluzione $\alpha$-approssimata con una probabilità di convergenza ad $1$ per $t\rightarrow+\infty$.
    \item \textbf{algoritmi essenzialmente $\alpha$-completi}: per alcune istanze $I\in\mathcal{I}$ si trova
          una soluzione $\alpha$-approssimata con una probabilità strettamente $<1$ per $t\rightarrow +\infty$.
\end{itemize}
Concludendo, ogni algoritmo fornisce compromessi tra :
\begin{itemize}
    \item una misura della qualità, descritta dalla soglia $\alpha$.
    \item una misura del tempo, descritta dalla soglia $t$.
\end{itemize}

\subsection{Diagrammi complessi}
\subsubsection{La probabilità di successo}
Sia la \textbf{probabilità di successo} $\pi_{A,n}=Pr[\delta_A(I,t)\leq\alpha | I\in\mathcal{I}_{n,\omega}\in\Omega]$ essere
la probabilità che l'algoritmo $A$ trovi in un tempo $\leq t$ una soluzione con una divergenza $\leq\alpha$
di istanze con dimensione $n$.

I due importanti parametri li abbiamo già visti sono la soglia $t$ che è collegata
all'efficienza dell'algoritmo, e la soglia $\alpha$ legata all'efficacia dell'algoritmo.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/prob_succ.png}
    \caption{Esempio di diagramma per la probabilità di successo}
\end{figure}
Come rappresentazione stiamo considerando il diagramma tri-dimensionale poiché
dipende da due variabili, la differenza relativa ed il tempo.

Da questo singolo diagramma è possibile estrarre altri tre classi di diagrammi "ausiliari",
questo tagliando lungo uno dei tre assi, quindi rispetto al tempo, qualità e probabilità.

\subsubsection{Qualified Run time Distribution diagram (QRTD)}
I diagrammi QRTD descrivono il profilo del tempo richiesto per raggiungere uno
specifico livello di qualità.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.55]{images/qrtd.png}
    \caption{Un esempio di diagramma QRTD}
\end{figure}
Se si sta cercando di raggiungere una certa qualità, allora il plot del diagramma
fornisce la probabilità di raggiungere tale qualità in un dato tempo. In
base alla tipologia di algoritmo l'ottimalità verrà raggiunta in dato tempo o
magari non raggiunta.
Il QRTD utile quando il tempo computazionale non è una risorsa scarsa.

Se l'algoritmo è:
\begin{itemize}
    \item completo, tutti i diagrammi raggiungono $1$ in un tempo finito (ottimalità sicuramente raggiunta).
    \item $\overline{\alpha}$-completo, tutti i diagrammi con $\alpha\geq\overline{\alpha}$
          raggiungono $1$ in tempo finito (l'ottimalità potrebbe essere raggiunta).
    \item $\overline{\alpha}$-incompleti, tutti i diagrammi con $\alpha\leq\overbrace{\alpha}$ non raggiungono $1$
          (l'ottimalità certamente non è raggiungibile).
\end{itemize}

\subsubsection{Timed Solution Quality Distribution diagram (TSQD)}
I diagrammi TSQD descrivono il profilo del livello di qualità
raggiunto in un dato tempo computazionale (qualità della soluzione relativa in un dato tempo).
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.45]{images/tsqd.png}
    \caption{Un esempio di diagramma TSQD}
\end{figure}
Il TSQD utile quando il tempo computazionale non è una risorsa scarsa.

Se l'algoritmo è:
\begin{itemize}
    \item completo, tutti i diagrammi con un sufficiente $t$ sono funzioni a scala in $\alpha=0$.
    \item $\overline{\alpha}$-completo, tutti i diagrammi con un sufficiente $t$ raggiungono $1$ in $\alpha=\overline{\alpha}$.
    \item probabilisticamente approssimativamente $\overline{\alpha}$-completo, i diagrammi convergono ad $1$ per $\alpha=\overline{\alpha}$
    \item $\overline{\alpha}$-completo, tutti i diagrammi mantengono una probabilità $<1$ per $\alpha=\overline{\alpha}$
\end{itemize}

\subsubsection{Solution Quality Statistics over Time diagram (SQST)}
Finalmente possiamo disegnare le linee dei livelli associati con i differenti quantili, come
rappresentato nella sottostante figura.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/sqst.png}
    \caption{Un esempio di diagramma SQST}
\end{figure}
Essi descrivono il compromesso tra qualità e tempo computazionale, nel caso di un algoritmo
\textit{robusto} le linee dei livelli sono molto vicine tra di loro. Questo è un diagramma
meno chiaro da leggere rispetto ad i precedenti. Supponiamo di essere interessati alla mediana
(linea puntinata), significa che vogliamo i risultati che impiegano almeno metà del tempo. Aspettando
$\approx20$ secondi una soluzione ottima potrà essere trovata (in metà del tempo rispetto ad un
quantile, tipo il terzo), invece
utilizzando un tempo minore una soluzione con qualità peggiore dovrà essere accettata.

\subsection{Wilcoxon's test}
I diagrammi ed i boxplot sono qualitativi, ma non sono veramente quantitativi. Per effettuare
una valutazione quantitativa della differenza empirica tra i due algoritmi può essere utilizzato
il \textbf{Wilcoxon's test} (il quale si concentra sull'efficacia seppur trascurando la robustezza).

\begin{enumerate}
    \item $f_{A_1}(I)-f_{A_2}(I)$ è uan variabile casuale definita su uno spazio delle istanze $\mathcal{I}$
    \item Formulare una \textbf{ipotesi nulla} (mancanza di relazione tra due fenomeni misurati) $H_0$
          secondo la quale la mediana teorica di $f_{A_1}(I).f_{A_2}(I)=0$
    \item Estrarre un campione di istanze $\ovcal{I}$ ed eseguire i due algoritmi su di esse, questo ci farà
          ottenere un campione di coppie di valori $(f_{A_1},f_{A_2})$.
    \item Calcolare la probabilità $p$ per ottenere i risultati osserva, o un risultato più "estremo",
          assumendo $H_0$ come vera.
    \item Impostare un livello significativo $\overline{p}$, il quale è la \textbf{probabilità massima accettabile}
          \begin{itemize}
              \item di rifiutare $H_0$ supponendo che sia vera.
              \item di considerare due mediane identiche come differenti.
              \item di considerare due algoritmi equivalenti come differentemente efficaci
                    (in riferimento alla mediana della divergenza).
          \end{itemize}
          e rifiutare $H_0$ quando $p<\overline{p}$
\end{enumerate}

I test statistici sono basati sulla formulazione di un ipotesi della \textbf{ipotesi nulla} $H_0$ in maniera
di comprendere la proprietà di osservare un certo comportamento empirico dato che tale ipotesi sia vera. In altre
parole, la nostra ipotesi nulla è che metà delle volte $f_{A_1}$ è meglio di $f_{A_2}$ e metà
delle volte è l'opposto. Questa è una buona  descrizione di due algoritmi equivalenti.

Valori tipici di $\overline{p}$ sono $5\%$ e $1\%$. Se la probabilità calcolata è più piccola,
allora $H_0$ è dimostrata falsa e rifiutata, e la mediana teorica tra gli algoritmi non sarà nulla.

\subsubsection{Ipotesi sul Wilcoxon's test}
Questo è un problema metodologico molto difficile. È un test \textbf{non parametrico}, il che
significa che non si sta ipotizzando su nulla a riguardo della distribuzione dei valori
testati. È utile valutare la prestazione degli algoritmi euristici, perché la distribuzione
dei risultati $f_A(I)$ è sconosciuta. È basato sulle seguenti ipotesi:
\begin{enumerate}
    \item Tutti i dati sono misurati su (almeno) una scala ordinata. Il valore specifico non
          è importante, solamente la dimensione relativa.

    \item I due data sets corrispondenti e derivano dalla stessa popolazione. Quindi applichiamo
          $A_1$ e $A_2$ alle stesse istanze estratte da $\mathcal{I}$.

    \item ogni coppia di valori è estratta indipendentemente da gli altri. Le istanze
          sono generate indipendentemente l'una dall'altra.
\end{enumerate}

La terza assunzione non è sempre verificata, quindi è necessario porre attenzione. Pensando
a qualche problema complicato come il Vehicle Routing problem. Generare differenti famiglie
di pesi sullo stesso grafo rende le istanza non proprio indipendenti l'una dall'altra.

Per eseguire il test devono essere seguiti i seguenti passi:
\begin{itemize}
    \item Calcolare la differenza assoluta $|f_{A_1}(I_i)-f_{A_2}(I_i)\text{   }\forall I_i\in\ovcal{I}$
    \item Ordinare quest'ultimi in ordine decrescente ed assegnare un \textbf{rango} (o \textit{rank})
          $R_i$ a ciascuno di essi.
    \item Sommare separatamente i ranghi delle coppie con una differenza positiva e quelli con
          una differenza negativa. Se l'ipotesi nulla $H_0$ risulta vera, allora le due somme dovrebbero
          essere uguali.
          \[
              \begin{cases}
                  W^+ =\sum_{i:f_{A_1}(I_i)>f_{A_2}(I_i)}R_i \\
                  W^- =\sum_{i:f_{A_1}(I_i)<f_{A_2}(I_i)}R_i
              \end{cases}
          \]
    \item La differenza tra $W^+-W^-$ permette di calcolare il valore di $p$: ognuna delle
          $|\ovcal{I}|$ differenze può essere positiva o negativa, sono quindi presenti $2^{|\ovcal{I}|}$
          possibilità. $p$ è la frazione con $|W^+-W^-|$ uguale o maggiore rispetto al valore osservato.
    \item Se $p<\overline{p}$, la differenze è significativa e:
          \begin{itemize}
              \item Se $W^<W^-$, l'algoritmo $A_1$ è migliore di $A_2$.
              \item Se $W^>W^-$, l'algoritmo $A_1$ è migliore di $A_2$.
          \end{itemize}
\end{itemize}

\subsubsection{Calcolo di $p$}
Il valore di $p$ è solitamente:
\begin{itemize}
    \item calcolato esplicitamente dall'enumerazione quando $|\ovcal{I}|<20$
    \item approssimato con una distribuzione normale quando $|\ovcal{I}|\geq 20$
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{images/p_val.png}
    \caption{Distribuzione del Wilcoxon's test per svariate dimensioni di campioni}
\end{figure}
Per esempio, supponiamo di avere tre istanze $I_1, I_2$ e $I_3$ le quali restituiscono
differenze con ranghi $1,2$ e $3$. La situazione più sbilanciata è quando $A_1$ o $A_2$
è sempre migliore dell'altro, quindi quando ci sono tre differenze positive o tre negative;
in altre parole potrebbe accadere che i ranghi $1,2$ e $3$ siano tutti ranghi di
differenze tutte positive o tutte negative.

Ogni valore quindi può essere "positivo" o "negativo" (nel senso che è un rango
di una differenza positiva o negativa), quindi sono presenti $2^3=8$ possibilità.

Ciascuna delle quali è generalmente equiprobabile, quindi gli $8$ casi possono essere
numerati, come nella figura in alto a sinistra. In un caso tutti sono positivi e restituisce
$W^+-W^-=(1+2+3)-0=6$; in un altro caso sono tutti negativi $W^+-W^-=0-(1+2+3)=-6$, e così via;
in due casi la differenza è $0$$W^+-W^-=(1+2)-3=3-(1+2)=0$.

    Ci si aspetta dall'ipotesi nulla di essere in uno dei due casi dove la differenza è uguale a $0$.
    Ma nel caso contrario, \textit{quale è la probabilità?} Assumendo che le due popolazioni
    siano le stesse così che la mediana sia su $0$, la probabilità di essere in una situazione
    di differenza \textbf{non equa o peggiore} corrisponde alla somma delle probabilità per
    ogni numerazione nel caso: per esempio, se la differenza restituita fosse $6$ la sua
    probabilità è $\frac{1}{8}$. Se la differenza ottenuta è $4$, la probabilità di ottenere
    ciò o peggio è $\frac{2}{8}$ e così via.

    Quindi può essere calcolata attraverso l'enumerazione, o se sono presenti molte istanze,
    la legge dei grandi numeri dice che va bene approssimare con una distribuzione normale.

    \paragraph{Possibili conclusioni}\mbox{}\\
    Il test di Wilcoxon può suggerire:
    \begin{itemize}
        \item che uno dei due algoritmi è significativamente migliroe dell'altro.
        \item che i due algoritmi sono statisticamente equivalenti.
    \end{itemize}
    In entrambi i casi è importante "tenere un occhio" su $p$, poiché è una risposta
    stocastica.

    Se il campione include istanze di tipi differenti, due algoritmi potrebbero essere
    complessivamente equivalenti, ma non equivalenti sulle singole istanze delle classi.
    Quindi se effettuo un test su $\delta_A(I)$ anziché $f_A(I)$? È una domanda aperta.
    I risultati possono essere differenti utilizzando $\delta_A(I)$ significa che dando
un peso minore alle istanze che hanno una soluzione ottimale maggiore. Probabilmente,
se il risultato del test è differente nei due casi, il testo è probabilmente non
affidabile.

\section{Euristiche costruttive}
Adesso che abbiamo fornito un ampia panoramica dei problemi e dei metodi di valutazione
degli algoritmi sia a priori che a posteriori, possiamo considerare la prima delle
tre classi di euristiche, le \textbf{euristiche costruttive}.

\subsection{Introduzione alle euristiche costruttive}
Per comprendere questo tipo di euristica dobbiamo ricordarci che i problemi di ottimizzazione
combinatoria ammettono delle soluzioni $x$ che sono sempre sottoinsiemi di
un dato ground set $B$, il quale è un insieme finito.

Il fatto che noi abbiamo sottoinsiemi suggerisce un possibile modo di costruire una soluzione,
ed in particolare le euristiche costruttive consistono nell'iniziare da un insieme vuoto
iniziale $\emptyset$ e man mano aggiungere un elemento alla volta finché non si \textit{intuisce}
che non ha senso introdurre nuovi elementi, terminando così l'algoritmo.
Analizziamo passo a passo questo processo, considerando il sottoinsieme $x^{(t)}$
aggiornato da una euristica costruttiva:
\begin{enumerate}
    \item Si inizia da un insieme vuoto: $x^{(0)}=\emptyset$ (il quale è ovviamente
    sottoinsieme di una qualsiasi soluzione ottima). Sappiamo già che attraverso la
    kernelization o utilizzando procedure di riduzione può essere dimostrato che
    alcuni elementi del ground set sono necessariamente inclusi in almeno una soluzione ottima.
    In tali casi, potrebbe essere una buona idea iniziare ad includere nel sottoinsieme originale
    questi elementi "forzati".

    \item Termina quando incontra una condizione di terminazione, il razionale di questa condizione
    consiste nel fatto che aggiungere un elemento nel sottoinsieme corrente non avrebbe alcun senso
    visto che non restituirebbe una soluzione ottima.

    \item Seleziona il \textit{"migliore"} elemento $i^{(t)}\in B$ tra quelli \textit{"accettabili"}
    allo step $t$.

    \item Aggiungi $i^{(t)}$ al sottoinsieme corrente $x^{(t)}:x^{(t+1)}:=x^{(t)}\cup\{ i^{(t)}\}$
    \item Tornare al passo $2$.
\end{enumerate}

\subsubsection{Il grafo di costruzione}
Il grafo di costruzione (\textbf{construction graph}), è lo strumento di modellazione principale
di questa costruttiva. Esso è un grafo diretto, costituito da nodi ed archi: i nodi di questo grafo
costituiscono l'insieme $\mathcal{F}_A$ ($F$ sta per \textit{find}), il quale è anche conosciuto come
\textbf{spazio di ricerca} (o \textit{search space}), il quale dipende dall'algoritmo $A$.

In altre parole $\mathcal{F}_A$ dipende dal \textit{problema} che si vuole risolvere, ma per lo stesso
problema possono esserci differenti spazi di ricerca corrispondenti a differenti
algoritmi, quindi differenti euristiche costruttive.

Lo spazio di ricerca è definito come la collezione di tutti i sottoinsiemi $x\subseteq B$ accettabili
per l'algoritmo $A$.
$$\mathcal{F}_A\subseteq 2^B$$
Ogni \textit{nodo} è un sottoinsieme ed alcuni saranno le soluzioni mentre altri no. Siamo interessati nei
sottoinsiemi che sono accettabili ed utili. Gli \textit{archi} connettono coppie di nodi,
l'arco in se è la collezione di tutte le coppie $(x,x\cup\{i\})$ tali che
$x\in \mathcal{F}_A ,i\in B\setminus x$ e $x\cup\{i\}\in \mathcal{F}_A$. Quindi, gli archi connettono
un sottoinsieme della soluzione ad un sottoinsieme leggermente più grande che rappresenta l'estensione
di un sottoinsieme ancora accettabile che include un nuovo elemento.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.6]{images/cons_graph.png}
    \caption{Il grafo di costruzione visita una sequenza di sotto insiemi che porta alla soluzione ottima}
\end{figure}
Questo grafo è un \textbf{DAG} (\textit{Directed Acyclic Graph}). Ogni possibile esecuzione di
$A$ è un \textbf{percorso massimo} del grafo di costruzione (contando sia il sottoinsieme
vuoto che un sottoinsieme la cui estensione non può essere accettata).

Il rettangolo del grafo di costruzione rappresenta le $2^B$, ovvero tutti i possibili
sottoinsiemi del ground set $B$. Questa collezione di sottoinsiemi
è partizione in classi che dipendono dalla loro cardinalità, quindi la prima classe (quella
più a sinistra) contiene solamente un possibile sottoinsieme, ovvero quello contenente l'insieme
vuoto $\emptyset$ (contenente tutti i sottoinsiemi di $0$ elementi). Nella seconda classe
dei sottoinsiemi possibili si trovano gli elementi singoli, poi le coppie, ecc. Sono
presenti $n+1$ classi che vanno da cardinalità $0$ fino a $n$. All'interno dell'insieme
potenza (o dei sottoinsiemi possibili), è presente lo spazio di ricerca degli algoritmi $\mathcal{F}_A$,
il quale contiene alcuni sottoinsiemi che sono considerati \textit{"utili"} per l'algoritmo: in
particolare contiene l'insieme vuoto (l'algoritmo parte da quello), e altri insiemi che ha senso
tenere conto.

Solitamente sottoinsiemi che sono al di fuori dello spazio di ricerca sono quelli che non hanno senso di
essere fissati, visto che non sono fattibili o perché non sono particolarmente "interessanti" ed
ogni altro sottoinsieme che non può essere raggiunto da $\mathcal{F}_A$ non è rilevante. Come prima
l'insieme delle soluzioni fattibili viene denotato con $X$, e l'insieme delle soluzioni ottime $X^*$.

Nell spazio di ricerca è presente un insieme di archi che connettono coppie di nodi, il secondo nodo
della coppia corrisponde al primo sottoinsieme della coppia più un certo elemento.

Come è possibile vedere dalle figure partire dal sottoinsieme vuoto è una soluzione accettabile,
le soluzioni non \textit{accettabili} si trovano al di fuori dello spazio di ricerca, e di fatti
non sono presenti archi che vanno al di fuori di questo. Quindi, ogni esecuzione di un algoritmo è un
percorso massimo all'interno del grafo di costruzione, che parte dal sottoinsieme vuoto e raggiunge
una soluzione, la quale idealmente dovrebbe essere ottimale o almeno fattibile. Nel caso ottimale,
il percorso termina quando incontra una soluzione ottima, questo è il caso degli
algoritmi di Dijkstra, Prim, Kruskal.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/cons_graph_1.png}
    \caption{Il grafo di costruzione visita una sequenza di sotto insiemi che porta ad una soluzione
    fattibile ma non ottimale}
\end{figure}

Negli altri casi, come nella figura sovrastante, il percorso potrebbe non terminare in una soluzione
ottima ma fattibile $x\in X$, questo è il caso degli algoritmi euristici come quelli usati per
KP e MDP.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.8]{images/cons_graph_2.png}
    \caption{Il grafo di costruzione visita una sequenza di sotto insiemi che porta ad una soluzione non fattibile}
\end{figure}
Il percorso potrebbe terminare in una soluzione non fattibile $x\notin X$ (ma accettabile poiché presente
nello spazio di ricerca), come per esempio il TSP su un grafo non completo.

\paragraph{Esempio di costruzione di grafi}\mbox{}\\
Un esempio di grafo di costruzione è quello per il TSP per trovare il Nearest-Neighbour in
un grafo completo. L'idea è quella di iniziare con un insieme di archi vuoto, quindi $x^{(0)}=\emptyset$,
e sono presenti $n-1$ archi uscenti.

La costruzione del grafo sarà un albero con $n-1$ archi e $n$ nodi; il numero di percorsi dall'insieme
vuoto alle foglie sarà esattamente $(n-1)!$, questo è il numero delle possibili esecuzioni
dell'algoritmo.

\paragraph{Proprietà dello spazio di ricerca}\mbox{}\\
\begin{itemize}
    \item Include l'insieme vuoto $\emptyset\in\mathcal{F}_A$, visto che ogni algoritmo generalmente
    inizia da quello.

    \item In generale include l'insieme delle soluzioni fattibili $X\subseteq\mathcal{F}_A$, a volte
    alcune soluzioni possono essere rimosse da esso nel caso in cui risultino ovviamente non ottimali:
    per esempio l'SCP dove inizia con un insieme vuoto di colonne ogni colonna è a aggiunta, in un
    dato punto la soluzione fattibile viene raggiunta ma non ha senso aggiungere
    altre colonne perché i nuovi sottoinsiemi saranno fattibili ma anche più costosi.

    \item I sottoinsiemi di $\mathcal{F}_A$ devono essere raggiungibili dal punto di partenza,
    altrimenti non avrebbe senso aggiungere una soluzione che non è raggiungibile dall'inizio. Un
    insieme candidato è la collezione delle \textbf{soluzioni parziali}, che sono le soluzioni
    generalmente non fattibili ma sono sottoinsiemi di soluzioni fattibili. Seguire una soluzione
    parziale fornisce almeno un percorso per una soluzione fattibile $\in X$.

\end{itemize}
\paragraph{Esempi di spazi di ricerca}\mbox{}\\
Lo spazio di ricerca potrebbe include tutte le soluzioni fattibili tali che:
$$\mathcal{F}_A\equiv X$$
come nel KP; potrebbe includere tutte le soluzioni parziali e tutte le soluzioni fattibili, tale che:
$$\mathcal{F}_A\equiv \bigcup_{x\in X} 2^x$$
per esempio nel MDP, nel quale non solo i sottoinsiemi dei $k$ punti sono considerati ma anche
quelli più piccoli o nell'algoritmo di Kruskal; lo spazio di ricerca potrebbe includere solo
alcune soluzioni parziali:
$$\mathcal{F}_A\subset \bigcup_{x\in X} 2^x$$
un esempio di questo è l'algoritmo di PRim per MSP, il quale non consider tutte le soluzioni
parziali ma considera un albero che è in aumento rimanendo connesso finché non diventa ricoprente.
Le soluzioni possono essere definite come uno speciale sottoinsieme non sufficiente per garantire
la fattibilità:
$$ U_{x\in X}2^x \mathcal{F}_A$$
un esempio di questo è il TSP, dove $\mathcal{F}_a$ può essere definito su tutti i
sottoinsiemi di archi che non includono diramazioni o sotto percorsi, non può
essere definito come "tutti i sottoinsiemi che fanno parte delle soluzioni fattibili"
visto che è un problema di decisione NP-completo.

\subsection{Condizione di terminazione}
Un euristica costruttiva $A$ termina in due casi. Quando il sottoinsieme corrente $x^{t}$
non può essere esteso senza che lasci lo spazio di ricerca $\mathcal{F}_A$ :
$$x^{(t)}\cup\{i\}\notin\mathcal{F}_A\text{   }\forall i\in B\setminus x^{(t)}$$
o in maniera pressoché equivalente, non ha un arco uscente:
$$\Delta_A^+(x^{(t)})=\{i\in B\setminus x^{(t)}:x^{(t)}\cup\{i\}\in\mathcal{F}_A\}$$

Sono possibili differenti comportamenti:
\begin{itemize}
    \item Talvolta tutti i sottoinsiemi visitati sono fattibili (es. KP).
    \item Di solito l'ultimo sottoinsieme è l'unica soluzione fattibile.
    \item $x^{(t)}$ potrebbe muoversi dentro e fuori $X$ (o $X^*$), seppur improbabile.
\end{itemize}

\section{Struttura di algoritmi euristici costruttivi}
\begin{algorithm}
    \caption{Pseudo codice - Euristica Costruttiva}
    \begin{algorithmic}
    \State $x:=\emptyset$
    \State $x^*:=\emptyset$

    \If{$x\in X$}
        \State $i \gets i-1$
    \Else
        \If{$i\leq 3$}
            \State $i \gets i+2$
        \EndIf
    \EndIf
    \end{algorithmic}
\end{algorithm}




\end{document}
